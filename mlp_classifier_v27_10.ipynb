{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNLjea1XHRGQjJM0Pj98y9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93b473b00d4f486d87e4476d89cac365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ed0a6bbd9654009a21bd0cd20df7b42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ec25a85cff74cabad84e5addff283be",
              "IPY_MODEL_5e00f95372504b749530a3e0d99cd93f"
            ]
          }
        },
        "9ed0a6bbd9654009a21bd0cd20df7b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ec25a85cff74cabad84e5addff283be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da32dc9a74544289811d20107b115ee9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2556ae2e425d445eb7d5ecf7ca83c72b"
          }
        },
        "5e00f95372504b749530a3e0d99cd93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aec48baff9bb456eb8257e9e6fdc92b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/557 [00:13&lt;00:00, 41.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c509a2820e1e4adc9fc5986ff0040bc6"
          }
        },
        "da32dc9a74544289811d20107b115ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2556ae2e425d445eb7d5ecf7ca83c72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aec48baff9bb456eb8257e9e6fdc92b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c509a2820e1e4adc9fc5986ff0040bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adec578bdd6b422f85951715e271c6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ac2b190a7e0458cbd99fe1e0d4d14e2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f24eb9072f22492b9e20cd5c328ad948",
              "IPY_MODEL_3ed50130bfe548c5a53ae917a4a77958"
            ]
          }
        },
        "4ac2b190a7e0458cbd99fe1e0d4d14e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f24eb9072f22492b9e20cd5c328ad948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8708249f0734349a55c933fb9023ae6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542923308,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542923308,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0cdda0ee2c0421c9cc52ebc22855045"
          }
        },
        "3ed50130bfe548c5a53ae917a4a77958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab5b8c9cf2ac45258e1bcb71d869a84d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 543M/543M [00:12&lt;00:00, 42.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9de082f4e04e4001991c8d936f1ce590"
          }
        },
        "b8708249f0734349a55c933fb9023ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0cdda0ee2c0421c9cc52ebc22855045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab5b8c9cf2ac45258e1bcb71d869a84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9de082f4e04e4001991c8d936f1ce590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf05f133c37d4c9b9ec9c3d6fa4e9942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cff43ea3b7db42aea68de28bf456c68a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a912a47bd9394945abe940331d5c5c98",
              "IPY_MODEL_fe82944439654b138eb1bd8aec52b3e8"
            ]
          }
        },
        "cff43ea3b7db42aea68de28bf456c68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a912a47bd9394945abe940331d5c5c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9af6238f1e84101badc31fdcfce00f2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8531be5c05b5483fbde43ebcd4ed7bd3"
          }
        },
        "fe82944439654b138eb1bd8aec52b3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5aea6dade9c440298d0f166e9d9ab9b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 895k/895k [00:00&lt;00:00, 1.55MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c4197592e2648eca65e97884eeb61a3"
          }
        },
        "b9af6238f1e84101badc31fdcfce00f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8531be5c05b5483fbde43ebcd4ed7bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5aea6dade9c440298d0f166e9d9ab9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c4197592e2648eca65e97884eeb61a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98e8d03d615f4f629cc4306117de6702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_399430fe04a84305a165e18cc262960d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_249b3e7a1b514b50be669a6b0cb0ed92",
              "IPY_MODEL_0c1ad09cf2364651982c6c52100243d9"
            ]
          }
        },
        "399430fe04a84305a165e18cc262960d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "249b3e7a1b514b50be669a6b0cb0ed92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fe9eac354a84835af0400efe1363364",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb34aa180e98437ebf0133297866eac5"
          }
        },
        "0c1ad09cf2364651982c6c52100243d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c0cbbca35544b2b84b1606999e9bd2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 4.90MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_829a0897732a45e6b31322c0310322b9"
          }
        },
        "2fe9eac354a84835af0400efe1363364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb34aa180e98437ebf0133297866eac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c0cbbca35544b2b84b1606999e9bd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "829a0897732a45e6b31322c0310322b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhlong1997/100-nlp-papers/blob/master/mlp_classifier_v27_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz79TpKNA6Ej",
        "outputId": "74d42f09-1ce8-49b4-e84f-78237e3ab9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-13 08:11:37--  https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.141.206\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.141.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 895321 (874K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 874.34K   966KB/s    in 0.9s    \n",
            "\n",
            "2020-10-13 08:11:38 (966 KB/s) - ‘vocab.txt’ saved [895321/895321]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7fFXvKt4Beo",
        "outputId": "b10b1c33-8eb6-4c51-803e-7a2642e96e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "\n",
        "    pairs = set(pairs)\n",
        "    return pairs\n",
        "print(get_pairs('Hôm_nay'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('n', 'a'), ('m', '_'), ('ô', 'm'), ('a', 'y'), ('_', 'n'), ('H', 'ô')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xgZ30tg4wMj",
        "outputId": "fef9017a-1d21-4e66-ac86-c96d87cf3596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('bpe.codes', encoding=\"utf-8\") as merges_handle:\n",
        "  merges = merges_handle.read().split(\"\\n\")[:-1]\n",
        "\n",
        "merges = [tuple(merge.split()[:-1]) for merge in merges]\n",
        "bpe_ranks = dict(zip(merges, range(len(merges))))\n",
        "cache = {}\n",
        "\n",
        "def bpe(token):\n",
        "  if token in cache:\n",
        "    return cache[token]\n",
        "  word = tuple(token)\n",
        "  word = tuple(list(word[:-1]) + [word[-1] + \"</w>\"])\n",
        "  pairs = get_pairs(word)\n",
        "\n",
        "  if not pairs:\n",
        "    return token\n",
        "\n",
        "  while True:\n",
        "    bigram = min(pairs, key=lambda pair: bpe_ranks.get(pair, float(\"inf\")))\n",
        "    if bigram not in bpe_ranks:\n",
        "      break\n",
        "    first, second = bigram\n",
        "    new_word = []\n",
        "    i = 0\n",
        "    while i < len(word):\n",
        "      try:\n",
        "        j = word.index(first, i)\n",
        "      except ValueError:\n",
        "        new_word.extend(word[i:])\n",
        "        break\n",
        "      else:\n",
        "        new_word.extend(word[i:j])\n",
        "        i = j\n",
        "\n",
        "      if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
        "        new_word.append(first + second)\n",
        "        i += 2\n",
        "      else:\n",
        "        new_word.append(word[i])\n",
        "        i += 1\n",
        "    new_word = tuple(new_word)\n",
        "    word = new_word\n",
        "    if len(word) == 1:\n",
        "      break\n",
        "    else:\n",
        "      pairs = get_pairs(word)\n",
        "  word = \"@@ \".join(word)\n",
        "  word = word[:-4]\n",
        "  cache[token] = word\n",
        "  return word\n",
        "\n",
        "print(bpe('Viblo'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vi@@ b@@ lo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWel1NUh7bxQ",
        "outputId": "7fd5fdd6-e8c2-4ee6-a7c1-fb7c129c478f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "def _tokenize(text):\n",
        "    \"\"\"Tokenize a string.\"\"\"\n",
        "    split_tokens = []\n",
        "\n",
        "    words = re.findall(r\"\\S+\\n?\", text)\n",
        "\n",
        "    for token in words:\n",
        "        split_tokens.extend([t for t in bpe(token).split(\" \")])\n",
        "    return split_tokens\n",
        "\n",
        "print(_tokenize('Hôm_nay trời nóng quá nên tôi ở nhà viết Viblo!'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hôm_nay', 'trời', 'nóng', 'quá', 'nên', 'tôi', 'ở', 'nhà', 'viết', 'Vi@@', 'blo@@', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6acVhfz9AZrF"
      },
      "source": [
        "encoder = {}\n",
        "bos_token=\"<s>\"\n",
        "eos_token=\"</s>\"\n",
        "sep_token=\"</s>\"\n",
        "cls_token=\"<s>\"\n",
        "unk_token=\"<unk>\"\n",
        "pad_token=\"<pad>\"\n",
        "mask_token=\"<mask>\"\n",
        "\n",
        "\n",
        "encoder[bos_token] = 0\n",
        "encoder[pad_token] = 1\n",
        "encoder[eos_token] = 2\n",
        "encoder[unk_token] = 3\n",
        "\n",
        "def add_from_file(f):\n",
        "  if isinstance(f, str):\n",
        "      try:\n",
        "          with open(f, \"r\", encoding=\"utf-8\") as fd:\n",
        "              add_from_file(fd)\n",
        "      except FileNotFoundError as fnfe:\n",
        "          raise fnfe\n",
        "      except UnicodeError:\n",
        "          raise Exception(\"Incorrect encoding detected in {}, please \" \"rebuild the dataset\".format(f))\n",
        "      return\n",
        "\n",
        "  lines = f.readlines()\n",
        "  for lineTmp in lines:\n",
        "      line = lineTmp.strip()\n",
        "      idx = line.rfind(\" \")\n",
        "      if idx == -1:\n",
        "          raise ValueError(\"Incorrect dictionary format, expected '<token> <cnt>'\")\n",
        "      word = line[:idx]\n",
        "      encoder[word] = len(encoder)\n",
        "\n",
        "add_from_file('vocab.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pcz9F29_Sgz",
        "outputId": "01213f3f-7b26-448a-c224-615aa34ab9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def _convert_token_to_id(token):\n",
        "    \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "    return encoder.get(token, encoder.get(unk_token))\n",
        "print(_convert_token_to_id('Hôm_nay'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v59YJ4MJF3xu",
        "outputId": "cc5b51c1-a994-4691-8924-4bbd31f36368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = {v: k for k, v in encoder.items()}\n",
        "def _convert_id_to_token(index):\n",
        "    return decoder.get(index, unk_token)\n",
        "\n",
        "print(_convert_id_to_token(7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "của\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iSccuIU7rn3",
        "outputId": "c47204ad-4001-4c85-9cfc-4a07bb27f884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def convert_tokens_to_string(tokens):\n",
        "    out_string = \" \".join(tokens)\n",
        "    out_string = out_string.replace(\"@@ \", \"\").strip()\n",
        "    out_string = out_string.replace('@@','').strip()\n",
        "    return out_string\n",
        "  \n",
        "print(convert_tokens_to_string(['Hôm_nay', 'trời', 'nóng', 'quá' ,'nên', 'tôi', 'ở', 'nhà', 'viết', 'Vi@@', 'blo@@']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hôm_nay trời nóng quá nên tôi ở nhà viết Viblo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGKL3T4d0l8J"
      },
      "source": [
        "# Requirement\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZTb_7oezVdQ",
        "outputId": "bb321d84-9139-4043-8ded-399139405eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install pandas\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLNQV9Y9Wf1l",
        "outputId": "dd1eb7c4-3f2b-487a-d007-f6a122fef8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 15.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=71f61c09a7f6d2c02577b42978d50f6a641bc64140901f28cf91c616f6a7f83b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0uUbDt0tmE",
        "outputId": "34437b41-5ed3-48ba-9e41-a06a559c8596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52mxnz7V4nMG",
        "outputId": "6c3a7ab1-2d85-4f64-df6e-270df5ed62c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! pip3 install vncorenlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=fe9207968868e12fd70ec0fe7746589ea7ef6292667c8e334b833140f1973fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niPCrVSQ4xWY"
      },
      "source": [
        "# ! rm -rf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhN1qnIx08Og",
        "outputId": "084fc8b9-c71a-4cd0-f8f0-ddc97838196c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "! mkdir -p vncorenlp/models/wordsegmenter\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "! mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "! mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "! mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-27 01:11:22--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412575 (26M) [application/octet-stream]\n",
            "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
            "\n",
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  34.3MB/s    in 0.8s    \n",
            "\n",
            "2020-10-27 01:11:24 (34.3 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
            "\n",
            "--2020-10-27 01:11:24--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 526544 (514K) [application/octet-stream]\n",
            "Saving to: ‘vi-vocab’\n",
            "\n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-10-27 01:11:24 (6.11 MB/s) - ‘vi-vocab’ saved [526544/526544]\n",
            "\n",
            "--2020-10-27 01:11:24--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128508 (125K) [text/plain]\n",
            "Saving to: ‘wordsegmenter.rdr’\n",
            "\n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-10-27 01:11:24 (3.03 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjjCGJ5I1Y41"
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "import re\n",
        "\n",
        "rdrsegmenter = VnCoreNLP(\"/content/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n",
        "def document_2_list_token(documents):\n",
        "  vocab = {}\n",
        "  for document in documents:\n",
        "    tokenizer = rdrsegmenter.tokenize(document)\n",
        "    for sentence in tokenizer:\n",
        "      for token in sentence:\n",
        "        token = token.lower()\n",
        "        if not re.search('[a-zA-Z]',token):\n",
        "          continue\n",
        "        if token != '':\n",
        "          if token not in vocab:\n",
        "            vocab[token] = 1\n",
        "          else:\n",
        "            vocab[token] += 1\n",
        "  return vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63AY4Ig04yd_",
        "outputId": "b5f89fde-9fc8-4819-dd92-d90dc6befc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(rdrsegmenter.tokenize('ban biet thu duong hoa phuong 1 son tra'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ban', 'biet', 'thu', 'duong', 'hoa', 'phuong', '1_son', 'tra']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrl9awb1Sz6W"
      },
      "source": [
        "# Entity Feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EurK-p8WP8t",
        "outputId": "7d37ab69-ae26-4720-addd-4cacc910308f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "93b473b00d4f486d87e4476d89cac365",
            "9ed0a6bbd9654009a21bd0cd20df7b42",
            "4ec25a85cff74cabad84e5addff283be",
            "5e00f95372504b749530a3e0d99cd93f",
            "da32dc9a74544289811d20107b115ee9",
            "2556ae2e425d445eb7d5ecf7ca83c72b",
            "aec48baff9bb456eb8257e9e6fdc92b8",
            "c509a2820e1e4adc9fc5986ff0040bc6",
            "adec578bdd6b422f85951715e271c6a6",
            "4ac2b190a7e0458cbd99fe1e0d4d14e2",
            "f24eb9072f22492b9e20cd5c328ad948",
            "3ed50130bfe548c5a53ae917a4a77958",
            "b8708249f0734349a55c933fb9023ae6",
            "a0cdda0ee2c0421c9cc52ebc22855045",
            "ab5b8c9cf2ac45258e1bcb71d869a84d",
            "9de082f4e04e4001991c8d936f1ce590",
            "bf05f133c37d4c9b9ec9c3d6fa4e9942",
            "cff43ea3b7db42aea68de28bf456c68a",
            "a912a47bd9394945abe940331d5c5c98",
            "fe82944439654b138eb1bd8aec52b3e8",
            "b9af6238f1e84101badc31fdcfce00f2",
            "8531be5c05b5483fbde43ebcd4ed7bd3",
            "5aea6dade9c440298d0f166e9d9ab9b2",
            "2c4197592e2648eca65e97884eeb61a3",
            "98e8d03d615f4f629cc4306117de6702",
            "399430fe04a84305a165e18cc262960d",
            "249b3e7a1b514b50be669a6b0cb0ed92",
            "0c1ad09cf2364651982c6c52100243d9",
            "2fe9eac354a84835af0400efe1363364",
            "cb34aa180e98437ebf0133297866eac5",
            "7c0cbbca35544b2b84b1606999e9bd2d",
            "829a0897732a45e6b31322c0310322b9"
          ]
        }
      },
      "source": [
        "import  torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from vncorenlp import VnCoreNLP\n",
        "import numpy as np\n",
        "\n",
        "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93b473b00d4f486d87e4476d89cac365",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adec578bdd6b422f85951715e271c6a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=542923308.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf05f133c37d4c9b9ec9c3d6fa4e9942",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98e8d03d615f4f629cc4306117de6702",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2bx-TMmX3qf"
      },
      "source": [
        "def get_token_line(text):\n",
        "  tokens_line = rdrsegmenter.tokenize(text)\n",
        "  line = \" \"\n",
        "  sentence = ''\n",
        "  for line in tokens_line:\n",
        "    line = ' '.join(token for token in tokens_line[0])\n",
        "    sentence += line + ' '\n",
        "    line = ' '\n",
        "  return sentence\n",
        "\n",
        "def get_token_list(text):\n",
        "  tokens_line = rdrsegmenter.tokenize(text)\n",
        "  sentence = []\n",
        "  for line in tokens_line:\n",
        "   sentence.extend(line)\n",
        "  return sentence\n",
        "\n",
        "def get_input_ids(text):\n",
        "  sentence = get_token_line(text)\n",
        "  input_id = torch.tensor([tokenizer.encode(sentence)])\n",
        "  return input_id\n",
        "\n",
        "def get_features_senten(text):\n",
        "  input_id = get_input_ids(text)\n",
        "  with torch.no_grad():\n",
        "      features = phobert(input_id)  \n",
        "  cls_token = features[0][0][0]\n",
        "  pooling = np.zeros(768)\n",
        "  for token in features[0][0]:\n",
        "    pooling = np.add(pooling,token)\n",
        "  return cls_token,pooling/(len(input_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASum3X3YX8vI"
      },
      "source": [
        "from scipy import spatial\n",
        "def similar_2_sen(text1 , text2, is_pooling = True):\n",
        "  text1 = text1.lower()\n",
        "  text2 = text2.lower()\n",
        "  cls_token1, pooling1 = get_features_senten(text1)\n",
        "  cls_token2, pooling2 = get_features_senten(text2)\n",
        "  if is_pooling:\n",
        "    vec1 = pooling1\n",
        "    vec2 = pooling2\n",
        "  else:\n",
        "    vec1 = cls_token1\n",
        "    vec2 = cls_token2\n",
        "  dataSetI = vec1.tolist()\n",
        "  dataSetII = vec2.tolist()\n",
        "  result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo2Kudn9YG7e"
      },
      "source": [
        "class_construction_land = ['là đất thổ cư','đất ở','trong đó thổ cư','đất ở lâu dài','thổ cư','diện tích xây dựng','diện tích sử dụng','nhà rộng','nhà xây','ont','diện tích đất ở','dt đất ở','dt sử dụng','dt nhà','diện tích nhà']\n",
        "other_type_land = ['diện tích vườn','diện tích ao','diện tích nông nghiệp','diện tích mái','diện tích sản xuất','đất trồng cây lâu năm']\n",
        "# other_type_land = []\n",
        "total_land = ['lô đất','tổng dt','tổng diện tích']\n",
        "# total_land =[]\n",
        "\n",
        "def computing_max_ability(text,class_area):\n",
        "  text = text.lower()\n",
        "  max = 0\n",
        "  context_ability = ''\n",
        "  class_patent = []\n",
        "  if class_area == 1:\n",
        "    class_patent = class_construction_land\n",
        "  if class_area == 2:\n",
        "    class_patent = other_type_land\n",
        "  if class_area == 3:\n",
        "    class_patent = total_land\n",
        "  for item in class_patent:\n",
        "    item = get_token_list(item)\n",
        "    item = ' '.join(x for x in item)\n",
        "    similar = similar_2_sen(text,item)\n",
        "    # print(text ,'------', item,'-----',similar)\n",
        "    if similar > max :\n",
        "      max = similar\n",
        "      context_ability = item\n",
        "  # print(context_ability)\n",
        "  return max "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G0F5zmaYMdb"
      },
      "source": [
        "import re\n",
        "def  clean_text(text):\n",
        "  text = re.sub('[:\\'\"|`~]','',text)\n",
        "  return text\n",
        "\n",
        "\n",
        "# print(clean_text('diện tích :'))\n",
        "class classifier_area:\n",
        "  def __init__(self, ner_result):\n",
        "    self.input = ner_result\n",
        "  \n",
        "  def get_position_of_area(self):\n",
        "    result = []\n",
        "    for item in self.input['labels']:\n",
        "      if item[2] == 'size':\n",
        "        result.append(item)  \n",
        "    return result\n",
        "      \n",
        "  def get_context_of_entity(self):\n",
        "    context_menu = []\n",
        "    position_area_entity = self.get_position_of_area()\n",
        "    for item in position_area_entity:\n",
        "      context_before = []\n",
        "      context_menu.append([item[0] , item[1]])\n",
        "#----------------------------------------------------------------      \n",
        "      if position_area_entity.index(item) > 0:\n",
        "        index_before = position_area_entity.index(item)\n",
        "        text_before = self.input['text'][position_area_entity[index_before - 1][1]:item[0]]\n",
        "        text_before = clean_text(text_before)\n",
        "      else:\n",
        "        text_before =  self.input['text'][:item[0]]\n",
        "      text_before = get_token_list(text_before)\n",
        "      text_before = list(text_before)\n",
        "      text_before.reverse()\n",
        "      # print((text_before))\n",
        "      end_senten_pattent = ['.',',','?','!','-','+',')','(','...']\n",
        "      if len(text_before) > 0:\n",
        "        if text_before[0] not in end_senten_pattent:\n",
        "          for token in text_before:\n",
        "            if token not in end_senten_pattent and len(context_before) < 3:\n",
        "              context_before.append(token)\n",
        "            else:\n",
        "              break\n",
        "      context_before.reverse()\n",
        "      if len(context_before) > 0:\n",
        "        context_menu[-1].append(' '.join(x for x in context_before))\n",
        "# -----------------------------------------------------------------------\n",
        "      context_after = []\n",
        "      if position_area_entity.index(item) < len(position_area_entity)-1:\n",
        "        index_after = position_area_entity.index(item)\n",
        "        text_after = self.input['text'][item[1]:position_area_entity[index_after+1][0]]\n",
        "        text_after = clean_text(text_after)\n",
        "      else:\n",
        "        text_after = self.input['text'][item[1]:]\n",
        "      text_after = list(get_token_list(text_after))\n",
        "      # print(text_after)\n",
        "      if len(text_after) > 0:\n",
        "        if text_after[0] not in end_senten_pattent:\n",
        "          for token in text_after:\n",
        "            if token not in end_senten_pattent and len(context_after) < 3:\n",
        "              context_after.append(token)\n",
        "            else:\n",
        "              break\n",
        "      if len(context_after) > 0:\n",
        "        context_menu[-1].append(' '.join(x for x in context_after))\n",
        "    return context_menu \n",
        "\n",
        "  def computing_similar(self):\n",
        "    labels = []\n",
        "    contexts = self.get_context_of_entity()\n",
        "    for context in contexts:\n",
        "      max = 0\n",
        "      classs = 0\n",
        "      context_text = context[2:]\n",
        "      # print(context_text)\n",
        "      for text in context_text:\n",
        "        for i in range(1,4):\n",
        "          computed = computing_max_ability(text,i)\n",
        "          # print(computed)\n",
        "          if max < computed:\n",
        "            max = computed\n",
        "            classs = i\n",
        "\n",
        "      labels.append(list([classs,max]))\n",
        "    return labels  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybNsOvcdYSD4"
      },
      "source": [
        "import re\n",
        "\n",
        "def get_number_floor(data):\n",
        "  map = {'một':'1', 'hai':'2', 'ba':'3', 'bốn':'4', 'năm':'5', 'sáu':'6', 'bảy':'7', 'tám':'8', 'chín':'9', 'không':'0'}\n",
        "  max_floor = 0 \n",
        "  text = ''\n",
        "  for item in data['labels']:\n",
        "    if 'floor' in item[2].split('_') :\n",
        "      # print(data['text'][item[0]:item[1]])\n",
        "      text = data['text'][item[0]:item[1]]\n",
        "      transform = ''\n",
        "      for item in text.split(' '):\n",
        "        if item in map : \n",
        "          transform += ' ' + map[item]\n",
        "        else:\n",
        "          transform +=' ' + item\n",
        "      text = transform\n",
        "      if re.search('(\\d+\\D\\d+)',text):\n",
        "        floor_patent = re.search('(\\d+\\D\\d+)',text).group()\n",
        "        if re.search('\\.|,',floor_patent):\n",
        "          floor = float(re.sub('\\D','.',floor_patent))\n",
        "        else:\n",
        "          floor = [float(x) for x in re.split('\\D+',floor_patent)]\n",
        "        # floor = [int(x) for x in floor]\n",
        "          floor =  max(floor)\n",
        "        if max_floor < floor:\n",
        "          max_floor = floor\n",
        "      else:\n",
        "        floor = text.split(' ')\n",
        "        for token in floor:\n",
        "          token = re.sub('\\D','',token)\n",
        "          if token.isdigit():\n",
        "            if float(token) > max_floor:\n",
        "              max_floor = float(token)\n",
        "        # print('floor',max_floor)\n",
        "        # if max_floor < floor:\n",
        "        #   max_floor = floor\n",
        "\n",
        "  if text == '':\n",
        "    return 0\n",
        "  return float(max_floor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfD0tgNoYXbC"
      },
      "source": [
        "import re\n",
        "def area_process(input):\n",
        "  classifier = classifier_area(input)\n",
        "  ability = classifier.computing_similar()\n",
        "  position = classifier.get_position_of_area()\n",
        "  # print(ability)\n",
        "  # print(position)\n",
        "  # 1/0\n",
        "  number_floor = get_number_floor(input)\n",
        "  if number_floor == 0:\n",
        "    number_floor =1\n",
        "  area = {'use_area':0,'total_land_area':0,'contruction_area':0}\n",
        "  area_content =  []\n",
        "  for item in position:\n",
        "    area_content.append(input['text'][item[0]:item[1]])\n",
        "  # print(area_content)\n",
        "\n",
        "  numberic_value =[]\n",
        "  for item in area_content:\n",
        "    item = item.lower()\n",
        "    if re.search('\\d*[\\.*,*]*\\d+\\s*(m|ha)',item):\n",
        "      value = re.search('\\d*[\\.*,*]*\\d+\\s*(m|ha)',item).group()\n",
        "      value = re.sub('m2','',value)\n",
        "      value = re.sub('ha','',value)\n",
        "      value = re.sub('m','',value)\n",
        "      value = re.sub(',','.',value)\n",
        "      # print(value)\n",
        "      # 1/0\n",
        "      try:\n",
        "        value = float(value)\n",
        "      except:\n",
        "        value = re.sub('\\D','',value)\n",
        "      numberic_value.append(float(value))\n",
        "\n",
        "  max_consistent_construction = 0\n",
        "  construction_value = 0\n",
        "  # print((numberic_value))\n",
        "  for index in range(len(numberic_value)):\n",
        "    # print(index)\n",
        "    classified = list(ability[index])\n",
        "    # print(classified)\n",
        "    # 1/0\n",
        "    if classified[0] ==  1:\n",
        "      if max_consistent_construction < classified[1] or (max_consistent_construction == classified[1] and numberic_value[index] < construction_value):\n",
        "        max_consistent_construction = classified[1]\n",
        "        construction_value = numberic_value[index]\n",
        "  # print(max_consistent_construction,construction_value)\n",
        "  max_total_area = 0\n",
        "  for index in range(len(numberic_value)):\n",
        "    classified = list(ability[index])\n",
        "    if numberic_value[index] > construction_value:\n",
        "    # if classified[1] < 0.53:\n",
        "      if max_total_area < numberic_value[index] and numberic_value[index] != number_floor*construction_value:\n",
        "        max_total_area = numberic_value[index]\n",
        "    # if classified[0] == 1 and max_total_area < numberic_value[index] and numberic_value[index] != number_floor*construction_value:\n",
        "      # max_total_area = numberic_value[index]\n",
        "  # print(max_total_area)\n",
        "  if max_total_area == 0:\n",
        "    max_total_area = construction_value\n",
        "  if construction_value == 0:\n",
        "    construction_value = max_total_area\n",
        "  # print('num floor:' , number_floor)\n",
        "  area['use_area'] = construction_value*number_floor\n",
        "  area['total_land_area'] = max_total_area\n",
        "  area['contruction_area'] = construction_value\n",
        "  return area"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPrxQSFkYcCk"
      },
      "source": [
        "def combine_house_entity(input):\n",
        "  area = area_process(input)\n",
        "  number_floor = get_number_floor(input)\n",
        "  slot = {'house_sizes':area,'house_description':{'floor':0,'mat_tien':'','size_mat_ngo':'','number_livingroom':'','number_kitchen':'','number_dressroom':'','number_bedroom':''},\n",
        "          'land_description':{},'price':0,'house_locate':{'near_places':'','location':''},'contact':{'contact_mobile':'','email':''}}\n",
        "  for item in input['labels']:\n",
        "    # print(item[2])\n",
        "    if item[2] in slot['house_description']:\n",
        "      if  slot['house_description'][item[2]] == '' or slot['house_description'][item[2]] == 0:\n",
        "        slot['house_description'][item[2]] = input['text'][item[0]:item[1]]\n",
        "      # print(slot['house_description'][item[2]])\n",
        "      # 1/0\n",
        "  \n",
        "    if item[2] in slot['house_locate']:\n",
        "      slot['house_locate'][item[2]] += input['text'][item[0]:item[1]] + ' '\n",
        "  \n",
        "    if item[2] in slot['contact']:\n",
        "      slot['contact'][item[2]] = input['text'][item[0]:item[1]]\n",
        "\n",
        "    if item[2] in slot:\n",
        "      slot[item[2]] = input['text'][item[0]:item[1]]\n",
        "  \n",
        "  slot['house_description']['floor'] = number_floor\n",
        "  # print(slot)\n",
        "  return slot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N90u2XHDYdg8",
        "outputId": "5fb0d4c8-72dc-423e-bb82-8cab3ec56f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(combine_house_entity(data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'house_sizes': {'use_area': 0, 'total_land_area': 0, 'contruction_area': 0}, 'house_description': {'floor': 0, 'mat_tien': '4m', 'size_mat_ngo': '', 'number_livingroom': '', 'number_kitchen': '', 'number_dressroom': '', 'number_bedroom': ''}, 'land_description': {}, 'price': 0, 'house_locate': {'near_places': 'đường Quốc Lộ 21B xóm 8 thông Đinh Xuyên Xã Hòa Nam ', 'location': ''}, 'contact': {'contact_mobile': '0914 415 ***', 'email': ''}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iy2De0536h3"
      },
      "source": [
        "# Content Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0RHqTbet4S6",
        "outputId": "92b2dfe4-2421-44b0-e606-e4c429fa29b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open('a.json','r',encoding='utf-8') as file:\n",
        "  data = json.load(file)\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cbSUDkxzZdM",
        "outputId": "d1c50b15-e191-475b-9b4a-55ac323dc750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from itertools import islice\n",
        "\n",
        "dfs = pd.read_excel('data_classifier.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "check_nan_land = dfs['land'].isnull()\n",
        "colum_land = list(dfs['land'])\n",
        "check_nan_house = dfs['house'].isnull()\n",
        "colum_house = list(dfs['house'])\n",
        "\n",
        "index_land = []\n",
        "index_house = []\n",
        "\n",
        "for index1 in range(len(colum_land)):\n",
        "  if not check_nan_land[index1]:\n",
        "    index_land.append(int(colum_land[index1]))\n",
        "\n",
        "for index1 in range(len(colum_house)):\n",
        "  if not check_nan_house[index1]:\n",
        "    index_house.append(int(colum_house[index1]))\n",
        "\n",
        "data_land = [data[index]['text'] for index in index_land]\n",
        "data_house = [data[index]['text'] for index in index_house]\n",
        "\n",
        "\n",
        "count_feature_land = document_2_list_token(data_land)\n",
        "count_feature_land = {k: v for k, v in sorted(count_feature_land.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# data_house = data_house[:index2]\n",
        "count_feature_house = document_2_list_token(data_house)\n",
        "count_feature_house = {k: v for k, v in sorted(count_feature_house.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "print(take(50,count_feature_land.items()))\n",
        "print(take(50,count_feature_house.items()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('có', 200), ('đất', 190), ('nhà', 139), ('bán', 109), ('cách', 82), ('đường', 81), ('giá', 74), ('chính', 67), ('chủ', 66), ('sổ_đỏ', 58), ('cấp', 57), ('khu', 57), ('gần', 55), ('và', 54), ('rất', 53), ('liên_hệ', 52), ('diện_tích', 51), ('cần', 47), ('lô', 42), ('hà_nội', 41), ('cho', 40), ('tỷ', 39), ('ô_tô', 38), ('đẹp', 38), ('trong', 36), ('chỉ', 36), ('nhà_đất', 35), ('nhu_cầu', 35), ('lại', 35), ('là', 33), ('vị_trí', 32), ('vuông_vắn', 32), ('được', 32), ('pháp_lý', 30), ('lh', 30), ('đầy_đủ', 27), ('rộng', 27), ('thuận_tiện', 27), ('m', 26), ('không', 26), ('làm', 26), ('tầng', 26), ('mảnh', 25), ('chợ', 25), ('thông_tin', 25), ('tại', 25), ('mặt_tiền', 24), ('vào', 24), ('an_ninh', 24), ('m2', 24)]\n",
            "[('nhà', 363), ('tầng', 299), ('phòng', 284), ('có', 143), ('cách', 136), ('chính', 122), ('gần', 119), ('giá', 112), ('ngủ', 112), ('tỷ', 110), ('sổ_đỏ', 108), ('bán', 106), ('chủ', 105), ('và', 104), ('đường', 99), ('bếp', 95), ('sân', 90), ('khu', 87), ('khách', 85), ('cửa', 76), ('rộng', 68), ('diện_tích', 68), ('pháp_lý', 68), ('vị_trí', 67), ('xây', 66), ('phơi', 63), ('chỉ', 63), ('thiết_kế', 62), ('gỗ', 62), ('ô_tô', 59), ('nội_thất', 59), ('các', 58), ('wc', 57), ('mới', 56), ('thờ', 55), ('đầy_đủ', 52), ('liên_hệ', 52), ('thoáng', 51), ('chợ', 51), ('rất', 50), ('m', 47), ('ngõ', 44), ('hỗ_trợ', 43), ('đẹp', 43), ('trường', 43), ('thương_lượng', 42), ('thanh_hà', 42), ('lh', 41), ('hướng', 40), ('trước', 40)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFERuDc77qfk"
      },
      "source": [
        "vocabulary_land = ['đất','nhà','lô','nhà_đất','vuông_vắn','vườn','mảnh','xưởng','kho']\n",
        "vocabulary_house = ['tầng','phòng','ngủ','bếp','khách','sân','thiết_kế','phơi','thờ','nội_thất','wc','hướng',',mặt_tiền','vệ_sinh','cửa','ban_công','tiện_nghi']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBRMeH-9GJK3",
        "outputId": "224c82b6-d1cb-4ffe-f1c6-b1ddb4f81afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = []\n",
        "  document = rdrsegmenter.tokenize(text)\n",
        "  for senten in document:\n",
        "    for token in senten:\n",
        "      tokens.append(token.lower())\n",
        "  return tokens\n",
        "\n",
        "def transform_document_to_vec(input):\n",
        "  text = input['text']\n",
        "  vocab = vocabulary_land\n",
        "  for item in vocabulary_house:\n",
        "    if item not in vocab:\n",
        "      vocab.append(item)\n",
        "  \n",
        "  text = text.lower()\n",
        "  vectorizer = CountVectorizer(tokenizer=tokenize,vocabulary=vocab,binary=True)\n",
        "  # print(vectorizer.build_tokenizer())\n",
        "  # 1/0\n",
        "  X = vectorizer.fit_transform([text]).toarray()\n",
        "  return X\n",
        "\n",
        "def transform_entity_to_vec(input):\n",
        "  slot = combine_house_entity(input)\n",
        "  vec = np.zeros(7)\n",
        "  for item in slot['house_description']:\n",
        "    if slot['house_description'][item] not in ['',0]:\n",
        "      vec[list(slot['house_description'].keys()).index(item)] = 1\n",
        "  return vec , slot\n",
        "\n",
        "# print(transform_entity_to_vec(data[1001]))\n",
        "# 1/0\n",
        "def convert_labels(y, C = 2):\n",
        "    Y = sparse.coo_matrix((np.ones_like(y),\n",
        "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
        "    return Y.T\n",
        "\n",
        "# a = transform_document_to_vec('Bán nhà 40m2x 3 tầng mới đường oto đỗ cửa giá 1.38 tỷ có TL ... Hướng : Đông Nam ... Diện tích : 40m2 nở hậu ... Vị trí : Nhà có vị trí cực thuận tiện gần trường học các cấp , công an phường , quân đội , nhà văn hóa . Nhà gần bãi gửi xe ngày đêm , đường trước nhà rộng 3 cực thoáng trong dãy phân lô cao tầng ... + Nhà gần trục đường 6 tuyến đi Hà Đông , Ngã Tư Sở , Mỹ Đình hay tuyến Chương Mỹ , Hòa Bình ... + Nhà gần nhiều dự án trọng đểm của quận Hà Đông là khu đang phát triển rất mạnh .. ... + Khu dân cư đông , an ninh tốt , hàng xóm thân thiện .. ... + Nhà gần điểm xe bus cách đường quốc lộ 6 chỉ 500m ... + Với tài chính vừa phải bạn sở hữu căn nhà lý tưởng ... Thiết kế : Theo kiến trúc tân cổ điển , rộng , thoáng , tầng 2 phòng ngủ ... + Tâng 1 : Phòng khách , để xe , bếp ăn riêng , có sân sau ... + Tầng 2 : 2 phòng ngủ rộng , 1 wc ... + Tầng 3 : 1 phòng ngủ , 1 phòng thờ , sân phơi rộng ... + Nhà có sân trước 3m , sân sau 1,5m các phòng đều có cửa sổ rộng , không khí lưu thông ... Nội thất : Hoàn thiện đầy đủ nội thất cơ bản , nhận nhà ngay ... Pháp lý : Giấy phép xây dựng riêng ... Sổ đỏ chính chủ ... Giá : 1.38 tỷ làm việc trực tiếp , bao sang tên ... Liên hệ : Tuấn Anh 0974322298 đi xem miễn phí ... Hỗ trợ thủ tục vay vốn ngân hàng 70% giá trị với lãi xuất thấp , thủ tục nhanh ... Thông tin pháp lý : Sổ đỏ chính chủ.')\n",
        "# print(a.shape)\n",
        "Feature_1 = []\n",
        "Feature_2 = []\n",
        "label = []\n",
        "for index in index_house:\n",
        "  print(index)\n",
        "  Feature_1.extend(transform_document_to_vec(data[index]))\n",
        "  Feature_2.append(transform_entity_to_vec(data[index])[0])\n",
        "  label.append(0)\n",
        "for index in index_land:\n",
        "  print(index)\n",
        "  Feature_1.extend(transform_document_to_vec(data[index]))\n",
        "  Feature_2.append(transform_entity_to_vec(data[index])[0])\n",
        "  label.append(1)\n",
        "Feature_1 = np.asarray(Feature_1)\n",
        "Feature_2 = np.asarray(Feature_2)\n",
        "Label     = np.asarray(label)\n",
        "print(Feature_2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "210\n",
            "287\n",
            "288\n",
            "289\n",
            "291\n",
            "290\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "299\n",
            "298\n",
            "301\n",
            "302\n",
            "304\n",
            "317\n",
            "328\n",
            "323\n",
            "330\n",
            "336\n",
            "332\n",
            "337\n",
            "338\n",
            "68\n",
            "70\n",
            "72\n",
            "73\n",
            "76\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "89\n",
            "90\n",
            "91\n",
            "343\n",
            "348\n",
            "350\n",
            "351\n",
            "352\n",
            "356\n",
            "258\n",
            "361\n",
            "360\n",
            "362\n",
            "366\n",
            "370\n",
            "373\n",
            "377\n",
            "383\n",
            "384\n",
            "387\n",
            "392\n",
            "394\n",
            "395\n",
            "399\n",
            "403\n",
            "406\n",
            "407\n",
            "408\n",
            "411\n",
            "413\n",
            "414\n",
            "415\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "424\n",
            "425\n",
            "427\n",
            "428\n",
            "430\n",
            "431\n",
            "433\n",
            "436\n",
            "437\n",
            "438\n",
            "441\n",
            "443\n",
            "447\n",
            "452\n",
            "453\n",
            "454\n",
            "463\n",
            "468\n",
            "482\n",
            "486\n",
            "488\n",
            "202\n",
            "209\n",
            "307\n",
            "329\n",
            "1\n",
            "6\n",
            "5\n",
            "7\n",
            "8\n",
            "12\n",
            "13\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "32\n",
            "34\n",
            "39\n",
            "40\n",
            "42\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "52\n",
            "53\n",
            "54\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "65\n",
            "63\n",
            "64\n",
            "67\n",
            "66\n",
            "70\n",
            "77\n",
            "78\n",
            "80\n",
            "355\n",
            "363\n",
            "364\n",
            "382\n",
            "388\n",
            "390\n",
            "391\n",
            "412\n",
            "4719\n",
            "4709\n",
            "4640\n",
            "4575\n",
            "4447\n",
            "4431\n",
            "4386\n",
            "4168\n",
            "3984\n",
            "3896\n",
            "3868\n",
            "3860\n",
            "3830\n",
            "3669\n",
            "3657\n",
            "3639\n",
            "3555\n",
            "3412\n",
            "3374\n",
            "3367\n",
            "3318\n",
            "3254\n",
            "3242\n",
            "3045\n",
            "2972\n",
            "2957\n",
            "2871\n",
            "2870\n",
            "2865\n",
            "2834\n",
            "2804\n",
            "2709\n",
            "2605\n",
            "2518\n",
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 0. 1. ... 1. 1. 1.]\n",
            " [1. 0. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT2r7_KM7p3i"
      },
      "source": [
        "# save feature for future use\n",
        "import numpy as np\n",
        "np.savez('123.npz', a=Feature_1, b=Feature_2, c=Label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jueqSEmjZ1pa",
        "outputId": "ef755813-3792-4bf6-9401-3312fe0a4d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(transform_entity_to_vec(data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0., 1., 0., 0., 0., 0., 0.]), {'house_sizes': {'use_area': 0, 'total_land_area': 0, 'contruction_area': 0}, 'house_description': {'floor': 0, 'mat_tien': '4m', 'size_mat_ngo': '', 'number_livingroom': '', 'number_kitchen': '', 'number_dressroom': '', 'number_bedroom': ''}, 'land_description': {}, 'price': 0, 'house_locate': {'near_places': 'đường Quốc Lộ 21B xóm 8 thông Đinh Xuyên Xã Hòa Nam ', 'location': ''}, 'contact': {'contact_mobile': '0914 415 ***', 'email': ''}})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3aIx8Dv1Rbp"
      },
      "source": [
        "# Load Feature saved\n",
        "Feature = np.load('123.npz',allow_pickle=True)\n",
        "a = Feature['a']\n",
        "b = Feature['b']\n",
        "c = Feature['c']\n",
        "print(b)\n",
        "\n",
        "index_array = range(a.shape[0])\n",
        "\n",
        "index_train, index_test = train_test_split(\n",
        "     index_array, test_size=0.33, random_state=42)\n",
        "# print(a[[1,2,3,4]])\n",
        "# print(index_train)\n",
        "# 1/0\n",
        "Feature1_train = a[index_train]\n",
        "Feature1_test = a[index_test]\n",
        "\n",
        "Feature2_train = b[index_train]\n",
        "Feature2_test = b[index_test]\n",
        "y_train = c[index_train]\n",
        "y_test = c[index_test]\n",
        "\n",
        "y_train =  convert_labels(y_train)\n",
        "y_test  =  convert_labels(y_test)\n",
        "print(Feature2_train.shape)\n",
        "print(Feature1_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5sUkwYqEHm0",
        "outputId": "c5908bac-0d4c-4e71-e27c-8e2d637c2fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y_train),len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiGxmYPvHQee",
        "outputId": "c83d5f03-287d-4039-96ba-b290eb660c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Feature1_train.shape , Feature2_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123, 26) (61, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG9hn3m0YPtW",
        "outputId": "0ac912fc-8d85-4f54-8752-4eec1a0401de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(Feature2_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 1.]\n",
            " [1. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1. 0. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 1.]\n",
            " [1. 1. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 0.]\n",
            " [1. 0. 1. 1. 1. 0. 1.]\n",
            " [1. 0. 0. 1. 1. 0. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 0. 1. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 1. 1. 0. 0. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 0. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 1. 0. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 0. 1.]\n",
            " [1. 0. 0. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 1. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLkYUPkE7rGm",
        "outputId": "a576f830-e0e1-411c-95db-eac57d37aa4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/thanhlong1997/bert_quora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_quora'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 630 (delta 21), reused 27 (delta 10), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (630/630), 219.91 KiB | 7.33 MiB/s, done.\n",
            "Resolving deltas: 100% (399/399), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktjm5dwVTF7r",
        "outputId": "e8329a07-572d-4857-a75a-25e3e09272ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Parameter\n",
        "learning_rate = 0.001\n",
        "epoch = 150\n",
        "batch_size = 128\n",
        "display_step =5\n",
        "\n",
        "#Network Parameters\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2 = 64\n",
        "dimention_1 = 26 # dimention of vocabulary\n",
        "dimention_2 = 7 # dimention of entities\n",
        "connect_dimention = 16 # dimention connect\n",
        "num_class = 2\n",
        "keep_prob = 0.7\n",
        "batch_size = 32\n",
        "\n",
        "# tf Graph input\n",
        "X_1 = tf.placeholder('float',[None,dimention_1],name='X_1')\n",
        "X_2 = tf.placeholder('float',[None,dimention_2],name='X_2')\n",
        "Y   = tf.placeholder('int64',[None,num_class],name='Y')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKMVXxVW5H1K"
      },
      "source": [
        "! tf_upgrade_v2 \\\n",
        "  --infile bert_quora/modeling.py \\\n",
        "  --outfile modeling_v2.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vzDYHFE4HON"
      },
      "source": [
        "# Store layers weight and bias\n",
        "\n",
        "weights = {\n",
        "    'concat_1': tf.Variable(tf.random_normal([dimention_1,connect_dimention]),name='concat_1'),\n",
        "    'concat_2': tf.Variable(tf.random_normal([dimention_2,connect_dimention]),name='concat_2'),\n",
        "    'h_1'     : tf.Variable(tf.random_normal([connect_dimention,n_hidden_1]),name='h_1'),\n",
        "    'h_2'     : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2]),name='h_2'),\n",
        "    'out'     : tf.Variable(tf.random_normal([n_hidden_2,num_class]),name='out')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b_1' : tf.Variable(tf.random_normal([n_hidden_1]),name='b_1'),\n",
        "    'b_2' : tf.Variable(tf.random_normal([n_hidden_2]),name='b_2'),\n",
        "    'out' : tf.Variable(tf.random_normal([num_class]),name='out')\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okTxSF0s-JRE"
      },
      "source": [
        "# Create model\n",
        "def neural_net(x1,x2):\n",
        "  # Concat Feature\n",
        "  concat  = tf.add(tf.matmul(x1,weights['concat_1']),tf.matmul(x2,weights['concat_2']))\n",
        "  # hidden layer 1\n",
        "  layer_1 = tf.add(tf.matmul(concat,weights['h_1']),biases['b_1'])\n",
        "  layer_norm1 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_1 = layer_norm1(layer_1)\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  # hidden layer 2\n",
        "  layer_2 = tf.add(tf.matmul(layer_1,weights['h_2']),biases['b_2'])\n",
        "  layer_norm2 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_2 = layer_norm2(layer_2)\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  # drop_out\n",
        "  drop_out = tf.nn.dropout(layer_2, keep_prob)\n",
        "  # out layer\n",
        "  out_layer = tf.add(tf.matmul(drop_out,weights['out']),biases['out'])\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  layer_norma = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  out_layer = layer_norma(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TSyMOgp_v-i",
        "outputId": "07cd2e3a-0814-4a9c-c467-8127a4869e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "logit = neural_net(X_1, X_2)\n",
        "\n",
        "# predict = tf.argmax(logit, axis=-1, output_type=tf.int32)\n",
        "# log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "# one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "# per_example_loss = -tf.reduce_sum(Y * log_probs, axis=-1)\n",
        "# loss_op = tf.reduce_mean(per_example_loss)\n",
        "# with tf.variable_scope(\"loss\"):\n",
        "    # I.e., 0.1 dropout\n",
        "    # output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    # logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    # logits = tf.nn.bias_add(logits, output_bias)\n",
        "# probabilities = tf.nn.softmax(logit, axis=-1)\n",
        "# log_probs = tf.nn.log_softmax(logit, axis=-1)\n",
        "\n",
        "    # one_hot_labels = tf.one_hot(Y, depth=num_class, dtype=tf.float32)\n",
        "\n",
        "# per_example_loss = -tf.reduce_sum(Y * log_probs, axis=-1)\n",
        "# loss_op = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "\n",
        "# total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
        "# loss \n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits = logit, labels = Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9qDsefjAuLC",
        "outputId": "50b85ec2-df51-4033-bd0f-925b3dc5bb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "def training(op):\n",
        "  if op == 'Adam':\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "  elif op == 'RMSprop':\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "  elif op == 'Momentum':\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate)\n",
        "  train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "  predict = tf.argmax(logit, 1)\n",
        "  correct_pred = tf.equal(tf.argmax(logit, 1),tf.argmax(Y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred , tf.float32))\n",
        "  # TP = tf.count_nonzero(tf.matmul(predict , Y))\n",
        "  # TN = tf.count_nonzero((predict - 1) * (Y - 1))\n",
        "  # FP = tf.count_nonzero(predict * (Y - 1))\n",
        "  # FN = tf.count_nonzero((predict - 1) * Y)\n",
        "  # precision = TP / (TP + FP)\n",
        "  # recall = TP / (TP + FN)\n",
        "  # f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "  loss_list = np.zeros(epoch)\n",
        "  init = tf.global_variables_initializer()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(epoch):\n",
        "      batch_feature1,batch_feature2, batch_y = Feature1_train ,Feature2_train, y_train\n",
        "      for i in range(0, (Feature1_train.shape[0] // batch_size) * batch_size, batch_size):\n",
        "        print('epoch',step,'batch',i)\n",
        "        batch_feature2 = Feature2_train[i:i+batch_size]\n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        loss, _ = sess.run([loss_op, train_op], \n",
        "                           feed_dict = {X_1 : np.zeros([batch_size,dimention_1]),\n",
        "                                        X_2 : batch_feature2, \n",
        "                                        Y : batch_label})\n",
        "        # train_loss += loss\n",
        "\n",
        "      # sess.run(train_op, feed_dict={X_1: batch_feature1,\n",
        "                                    # X_2:batch_feature2,\n",
        "                                    # Y :batch_y})\n",
        "      loss , acc , pred,log = sess.run([loss_op, accuracy,predict,logit],feed_dict={X_1: np.zeros([batch_feature1.shape[0],dimention_1]),\n",
        "                                                                                    X_2: Feature2_train,\n",
        "                                                                                    Y : y_train})\n",
        "      # prop = sess.run([probabilities],feed_dict ={X_1: batch_x,\n",
        "                                                  # X_2: np.zeros([batch_x.shape[0],dimention_2])} )\n",
        "      loss_list[step] = loss\n",
        "      if step % display_step == 0 or step == 1:\n",
        "        print('Step '+str(step)+' batch loss = '+ '{:.4f}'.format(loss) + ' trainning acc ='+\n",
        "              '{:.3f}'.format(acc))\n",
        "        save_path = saver.save(sess, \"/content/model/model\" + str(step)+ \".ckpt\")\n",
        "        print(\"Model saved in path: %s\" % save_path)\n",
        "        batch_y_true = np.argmax(y_train, 1)\n",
        "        print(batch_y_true.shape)\n",
        "        print(f1_score(batch_y_true, pred, average='micro'))\n",
        "        print(pred.shape)\n",
        "    print('Testing Acc:',sess.run(accuracy,feed_dict={X_1: np.zeros([Feature1_test.shape[0],dimention_1]),\n",
        "                                                      X_2: Feature2_test,\n",
        "                                                      Y  : y_test}))\n",
        "    test_result = sess.run(predict,feed_dict={X_1: np.zeros([Feature1_test.shape[0],dimention_1]),\n",
        "                                              X_2: Feature2_test,\n",
        "                                              Y  :y_test})\n",
        "    test_true = np.argmax(y_test, 1)\n",
        "    print(f1_score(test_true,test_result, average='micro'))\n",
        "    print(test_result)\n",
        "    print(test_true)\n",
        "  return loss_list\n",
        "\n",
        "adam = training('Adam') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 batch 0\n",
            "epoch 0 batch 32\n",
            "epoch 0 batch 64\n",
            "Step 0 batch loss = 1.0335 trainning acc =0.545\n",
            "Model saved in path: /content/model/model0.ckpt\n",
            "(123,)\n",
            "0.5447154471544715\n",
            "(123,)\n",
            "epoch 1 batch 0\n",
            "epoch 1 batch 32\n",
            "epoch 1 batch 64\n",
            "Step 1 batch loss = 0.9695 trainning acc =0.577\n",
            "Model saved in path: /content/model/model1.ckpt\n",
            "(123,)\n",
            "0.5772357723577236\n",
            "(123,)\n",
            "epoch 2 batch 0\n",
            "epoch 2 batch 32\n",
            "epoch 2 batch 64\n",
            "epoch 3 batch 0\n",
            "epoch 3 batch 32\n",
            "epoch 3 batch 64\n",
            "epoch 4 batch 0\n",
            "epoch 4 batch 32\n",
            "epoch 4 batch 64\n",
            "epoch 5 batch 0\n",
            "epoch 5 batch 32\n",
            "epoch 5 batch 64\n",
            "Step 5 batch loss = 0.8139 trainning acc =0.650\n",
            "Model saved in path: /content/model/model5.ckpt\n",
            "(123,)\n",
            "0.6504065040650406\n",
            "(123,)\n",
            "epoch 6 batch 0\n",
            "epoch 6 batch 32\n",
            "epoch 6 batch 64\n",
            "epoch 7 batch 0\n",
            "epoch 7 batch 32\n",
            "epoch 7 batch 64\n",
            "epoch 8 batch 0\n",
            "epoch 8 batch 32\n",
            "epoch 8 batch 64\n",
            "epoch 9 batch 0\n",
            "epoch 9 batch 32\n",
            "epoch 9 batch 64\n",
            "epoch 10 batch 0\n",
            "epoch 10 batch 32\n",
            "epoch 10 batch 64\n",
            "Step 10 batch loss = 0.5602 trainning acc =0.780\n",
            "Model saved in path: /content/model/model10.ckpt\n",
            "(123,)\n",
            "0.7804878048780488\n",
            "(123,)\n",
            "epoch 11 batch 0\n",
            "epoch 11 batch 32\n",
            "epoch 11 batch 64\n",
            "epoch 12 batch 0\n",
            "epoch 12 batch 32\n",
            "epoch 12 batch 64\n",
            "epoch 13 batch 0\n",
            "epoch 13 batch 32\n",
            "epoch 13 batch 64\n",
            "epoch 14 batch 0\n",
            "epoch 14 batch 32\n",
            "epoch 14 batch 64\n",
            "epoch 15 batch 0\n",
            "epoch 15 batch 32\n",
            "epoch 15 batch 64\n",
            "Step 15 batch loss = 0.5398 trainning acc =0.789\n",
            "Model saved in path: /content/model/model15.ckpt\n",
            "(123,)\n",
            "0.7886178861788617\n",
            "(123,)\n",
            "epoch 16 batch 0\n",
            "epoch 16 batch 32\n",
            "epoch 16 batch 64\n",
            "epoch 17 batch 0\n",
            "epoch 17 batch 32\n",
            "epoch 17 batch 64\n",
            "epoch 18 batch 0\n",
            "epoch 18 batch 32\n",
            "epoch 18 batch 64\n",
            "epoch 19 batch 0\n",
            "epoch 19 batch 32\n",
            "epoch 19 batch 64\n",
            "epoch 20 batch 0\n",
            "epoch 20 batch 32\n",
            "epoch 20 batch 64\n",
            "Step 20 batch loss = 0.5549 trainning acc =0.780\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Model saved in path: /content/model/model20.ckpt\n",
            "(123,)\n",
            "0.7804878048780488\n",
            "(123,)\n",
            "epoch 21 batch 0\n",
            "epoch 21 batch 32\n",
            "epoch 21 batch 64\n",
            "epoch 22 batch 0\n",
            "epoch 22 batch 32\n",
            "epoch 22 batch 64\n",
            "epoch 23 batch 0\n",
            "epoch 23 batch 32\n",
            "epoch 23 batch 64\n",
            "epoch 24 batch 0\n",
            "epoch 24 batch 32\n",
            "epoch 24 batch 64\n",
            "epoch 25 batch 0\n",
            "epoch 25 batch 32\n",
            "epoch 25 batch 64\n",
            "Step 25 batch loss = 0.4798 trainning acc =0.821\n",
            "Model saved in path: /content/model/model25.ckpt\n",
            "(123,)\n",
            "0.8211382113821138\n",
            "(123,)\n",
            "epoch 26 batch 0\n",
            "epoch 26 batch 32\n",
            "epoch 26 batch 64\n",
            "epoch 27 batch 0\n",
            "epoch 27 batch 32\n",
            "epoch 27 batch 64\n",
            "epoch 28 batch 0\n",
            "epoch 28 batch 32\n",
            "epoch 28 batch 64\n",
            "epoch 29 batch 0\n",
            "epoch 29 batch 32\n",
            "epoch 29 batch 64\n",
            "epoch 30 batch 0\n",
            "epoch 30 batch 32\n",
            "epoch 30 batch 64\n",
            "Step 30 batch loss = 0.4537 trainning acc =0.829\n",
            "Model saved in path: /content/model/model30.ckpt\n",
            "(123,)\n",
            "0.8292682926829268\n",
            "(123,)\n",
            "epoch 31 batch 0\n",
            "epoch 31 batch 32\n",
            "epoch 31 batch 64\n",
            "epoch 32 batch 0\n",
            "epoch 32 batch 32\n",
            "epoch 32 batch 64\n",
            "epoch 33 batch 0\n",
            "epoch 33 batch 32\n",
            "epoch 33 batch 64\n",
            "epoch 34 batch 0\n",
            "epoch 34 batch 32\n",
            "epoch 34 batch 64\n",
            "epoch 35 batch 0\n",
            "epoch 35 batch 32\n",
            "epoch 35 batch 64\n",
            "Step 35 batch loss = 0.4473 trainning acc =0.837\n",
            "Model saved in path: /content/model/model35.ckpt\n",
            "(123,)\n",
            "0.8373983739837398\n",
            "(123,)\n",
            "epoch 36 batch 0\n",
            "epoch 36 batch 32\n",
            "epoch 36 batch 64\n",
            "epoch 37 batch 0\n",
            "epoch 37 batch 32\n",
            "epoch 37 batch 64\n",
            "epoch 38 batch 0\n",
            "epoch 38 batch 32\n",
            "epoch 38 batch 64\n",
            "epoch 39 batch 0\n",
            "epoch 39 batch 32\n",
            "epoch 39 batch 64\n",
            "epoch 40 batch 0\n",
            "epoch 40 batch 32\n",
            "epoch 40 batch 64\n",
            "Step 40 batch loss = 0.3414 trainning acc =0.894\n",
            "Model saved in path: /content/model/model40.ckpt\n",
            "(123,)\n",
            "0.8943089430894309\n",
            "(123,)\n",
            "epoch 41 batch 0\n",
            "epoch 41 batch 32\n",
            "epoch 41 batch 64\n",
            "epoch 42 batch 0\n",
            "epoch 42 batch 32\n",
            "epoch 42 batch 64\n",
            "epoch 43 batch 0\n",
            "epoch 43 batch 32\n",
            "epoch 43 batch 64\n",
            "epoch 44 batch 0\n",
            "epoch 44 batch 32\n",
            "epoch 44 batch 64\n",
            "epoch 45 batch 0\n",
            "epoch 45 batch 32\n",
            "epoch 45 batch 64\n",
            "Step 45 batch loss = 0.4162 trainning acc =0.854\n",
            "Model saved in path: /content/model/model45.ckpt\n",
            "(123,)\n",
            "0.8536585365853658\n",
            "(123,)\n",
            "epoch 46 batch 0\n",
            "epoch 46 batch 32\n",
            "epoch 46 batch 64\n",
            "epoch 47 batch 0\n",
            "epoch 47 batch 32\n",
            "epoch 47 batch 64\n",
            "epoch 48 batch 0\n",
            "epoch 48 batch 32\n",
            "epoch 48 batch 64\n",
            "epoch 49 batch 0\n",
            "epoch 49 batch 32\n",
            "epoch 49 batch 64\n",
            "epoch 50 batch 0\n",
            "epoch 50 batch 32\n",
            "epoch 50 batch 64\n",
            "Step 50 batch loss = 0.3773 trainning acc =0.870\n",
            "Model saved in path: /content/model/model50.ckpt\n",
            "(123,)\n",
            "0.8699186991869918\n",
            "(123,)\n",
            "epoch 51 batch 0\n",
            "epoch 51 batch 32\n",
            "epoch 51 batch 64\n",
            "epoch 52 batch 0\n",
            "epoch 52 batch 32\n",
            "epoch 52 batch 64\n",
            "epoch 53 batch 0\n",
            "epoch 53 batch 32\n",
            "epoch 53 batch 64\n",
            "epoch 54 batch 0\n",
            "epoch 54 batch 32\n",
            "epoch 54 batch 64\n",
            "epoch 55 batch 0\n",
            "epoch 55 batch 32\n",
            "epoch 55 batch 64\n",
            "Step 55 batch loss = 0.3543 trainning acc =0.886\n",
            "Model saved in path: /content/model/model55.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 56 batch 0\n",
            "epoch 56 batch 32\n",
            "epoch 56 batch 64\n",
            "epoch 57 batch 0\n",
            "epoch 57 batch 32\n",
            "epoch 57 batch 64\n",
            "epoch 58 batch 0\n",
            "epoch 58 batch 32\n",
            "epoch 58 batch 64\n",
            "epoch 59 batch 0\n",
            "epoch 59 batch 32\n",
            "epoch 59 batch 64\n",
            "epoch 60 batch 0\n",
            "epoch 60 batch 32\n",
            "epoch 60 batch 64\n",
            "Step 60 batch loss = 0.4013 trainning acc =0.862\n",
            "Model saved in path: /content/model/model60.ckpt\n",
            "(123,)\n",
            "0.861788617886179\n",
            "(123,)\n",
            "epoch 61 batch 0\n",
            "epoch 61 batch 32\n",
            "epoch 61 batch 64\n",
            "epoch 62 batch 0\n",
            "epoch 62 batch 32\n",
            "epoch 62 batch 64\n",
            "epoch 63 batch 0\n",
            "epoch 63 batch 32\n",
            "epoch 63 batch 64\n",
            "epoch 64 batch 0\n",
            "epoch 64 batch 32\n",
            "epoch 64 batch 64\n",
            "epoch 65 batch 0\n",
            "epoch 65 batch 32\n",
            "epoch 65 batch 64\n",
            "Step 65 batch loss = 0.3701 trainning acc =0.878\n",
            "Model saved in path: /content/model/model65.ckpt\n",
            "(123,)\n",
            "0.8780487804878049\n",
            "(123,)\n",
            "epoch 66 batch 0\n",
            "epoch 66 batch 32\n",
            "epoch 66 batch 64\n",
            "epoch 67 batch 0\n",
            "epoch 67 batch 32\n",
            "epoch 67 batch 64\n",
            "epoch 68 batch 0\n",
            "epoch 68 batch 32\n",
            "epoch 68 batch 64\n",
            "epoch 69 batch 0\n",
            "epoch 69 batch 32\n",
            "epoch 69 batch 64\n",
            "epoch 70 batch 0\n",
            "epoch 70 batch 32\n",
            "epoch 70 batch 64\n",
            "Step 70 batch loss = 0.3532 trainning acc =0.886\n",
            "Model saved in path: /content/model/model70.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 71 batch 0\n",
            "epoch 71 batch 32\n",
            "epoch 71 batch 64\n",
            "epoch 72 batch 0\n",
            "epoch 72 batch 32\n",
            "epoch 72 batch 64\n",
            "epoch 73 batch 0\n",
            "epoch 73 batch 32\n",
            "epoch 73 batch 64\n",
            "epoch 74 batch 0\n",
            "epoch 74 batch 32\n",
            "epoch 74 batch 64\n",
            "epoch 75 batch 0\n",
            "epoch 75 batch 32\n",
            "epoch 75 batch 64\n",
            "Step 75 batch loss = 0.3551 trainning acc =0.886\n",
            "Model saved in path: /content/model/model75.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 76 batch 0\n",
            "epoch 76 batch 32\n",
            "epoch 76 batch 64\n",
            "epoch 77 batch 0\n",
            "epoch 77 batch 32\n",
            "epoch 77 batch 64\n",
            "epoch 78 batch 0\n",
            "epoch 78 batch 32\n",
            "epoch 78 batch 64\n",
            "epoch 79 batch 0\n",
            "epoch 79 batch 32\n",
            "epoch 79 batch 64\n",
            "epoch 80 batch 0\n",
            "epoch 80 batch 32\n",
            "epoch 80 batch 64\n",
            "Step 80 batch loss = 0.3537 trainning acc =0.886\n",
            "Model saved in path: /content/model/model80.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 81 batch 0\n",
            "epoch 81 batch 32\n",
            "epoch 81 batch 64\n",
            "epoch 82 batch 0\n",
            "epoch 82 batch 32\n",
            "epoch 82 batch 64\n",
            "epoch 83 batch 0\n",
            "epoch 83 batch 32\n",
            "epoch 83 batch 64\n",
            "epoch 84 batch 0\n",
            "epoch 84 batch 32\n",
            "epoch 84 batch 64\n",
            "epoch 85 batch 0\n",
            "epoch 85 batch 32\n",
            "epoch 85 batch 64\n",
            "Step 85 batch loss = 0.3675 trainning acc =0.878\n",
            "Model saved in path: /content/model/model85.ckpt\n",
            "(123,)\n",
            "0.8780487804878049\n",
            "(123,)\n",
            "epoch 86 batch 0\n",
            "epoch 86 batch 32\n",
            "epoch 86 batch 64\n",
            "epoch 87 batch 0\n",
            "epoch 87 batch 32\n",
            "epoch 87 batch 64\n",
            "epoch 88 batch 0\n",
            "epoch 88 batch 32\n",
            "epoch 88 batch 64\n",
            "epoch 89 batch 0\n",
            "epoch 89 batch 32\n",
            "epoch 89 batch 64\n",
            "epoch 90 batch 0\n",
            "epoch 90 batch 32\n",
            "epoch 90 batch 64\n",
            "Step 90 batch loss = 0.3433 trainning acc =0.886\n",
            "Model saved in path: /content/model/model90.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 91 batch 0\n",
            "epoch 91 batch 32\n",
            "epoch 91 batch 64\n",
            "epoch 92 batch 0\n",
            "epoch 92 batch 32\n",
            "epoch 92 batch 64\n",
            "epoch 93 batch 0\n",
            "epoch 93 batch 32\n",
            "epoch 93 batch 64\n",
            "epoch 94 batch 0\n",
            "epoch 94 batch 32\n",
            "epoch 94 batch 64\n",
            "epoch 95 batch 0\n",
            "epoch 95 batch 32\n",
            "epoch 95 batch 64\n",
            "Step 95 batch loss = 0.3363 trainning acc =0.894\n",
            "Model saved in path: /content/model/model95.ckpt\n",
            "(123,)\n",
            "0.8943089430894309\n",
            "(123,)\n",
            "epoch 96 batch 0\n",
            "epoch 96 batch 32\n",
            "epoch 96 batch 64\n",
            "epoch 97 batch 0\n",
            "epoch 97 batch 32\n",
            "epoch 97 batch 64\n",
            "epoch 98 batch 0\n",
            "epoch 98 batch 32\n",
            "epoch 98 batch 64\n",
            "epoch 99 batch 0\n",
            "epoch 99 batch 32\n",
            "epoch 99 batch 64\n",
            "epoch 100 batch 0\n",
            "epoch 100 batch 32\n",
            "epoch 100 batch 64\n",
            "Step 100 batch loss = 0.3953 trainning acc =0.862\n",
            "Model saved in path: /content/model/model100.ckpt\n",
            "(123,)\n",
            "0.861788617886179\n",
            "(123,)\n",
            "epoch 101 batch 0\n",
            "epoch 101 batch 32\n",
            "epoch 101 batch 64\n",
            "epoch 102 batch 0\n",
            "epoch 102 batch 32\n",
            "epoch 102 batch 64\n",
            "epoch 103 batch 0\n",
            "epoch 103 batch 32\n",
            "epoch 103 batch 64\n",
            "epoch 104 batch 0\n",
            "epoch 104 batch 32\n",
            "epoch 104 batch 64\n",
            "epoch 105 batch 0\n",
            "epoch 105 batch 32\n",
            "epoch 105 batch 64\n",
            "Step 105 batch loss = 0.3360 trainning acc =0.894\n",
            "Model saved in path: /content/model/model105.ckpt\n",
            "(123,)\n",
            "0.8943089430894309\n",
            "(123,)\n",
            "epoch 106 batch 0\n",
            "epoch 106 batch 32\n",
            "epoch 106 batch 64\n",
            "epoch 107 batch 0\n",
            "epoch 107 batch 32\n",
            "epoch 107 batch 64\n",
            "epoch 108 batch 0\n",
            "epoch 108 batch 32\n",
            "epoch 108 batch 64\n",
            "epoch 109 batch 0\n",
            "epoch 109 batch 32\n",
            "epoch 109 batch 64\n",
            "epoch 110 batch 0\n",
            "epoch 110 batch 32\n",
            "epoch 110 batch 64\n",
            "Step 110 batch loss = 0.3494 trainning acc =0.886\n",
            "Model saved in path: /content/model/model110.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 111 batch 0\n",
            "epoch 111 batch 32\n",
            "epoch 111 batch 64\n",
            "epoch 112 batch 0\n",
            "epoch 112 batch 32\n",
            "epoch 112 batch 64\n",
            "epoch 113 batch 0\n",
            "epoch 113 batch 32\n",
            "epoch 113 batch 64\n",
            "epoch 114 batch 0\n",
            "epoch 114 batch 32\n",
            "epoch 114 batch 64\n",
            "epoch 115 batch 0\n",
            "epoch 115 batch 32\n",
            "epoch 115 batch 64\n",
            "Step 115 batch loss = 0.3497 trainning acc =0.886\n",
            "Model saved in path: /content/model/model115.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 116 batch 0\n",
            "epoch 116 batch 32\n",
            "epoch 116 batch 64\n",
            "epoch 117 batch 0\n",
            "epoch 117 batch 32\n",
            "epoch 117 batch 64\n",
            "epoch 118 batch 0\n",
            "epoch 118 batch 32\n",
            "epoch 118 batch 64\n",
            "epoch 119 batch 0\n",
            "epoch 119 batch 32\n",
            "epoch 119 batch 64\n",
            "epoch 120 batch 0\n",
            "epoch 120 batch 32\n",
            "epoch 120 batch 64\n",
            "Step 120 batch loss = 0.3495 trainning acc =0.886\n",
            "Model saved in path: /content/model/model120.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 121 batch 0\n",
            "epoch 121 batch 32\n",
            "epoch 121 batch 64\n",
            "epoch 122 batch 0\n",
            "epoch 122 batch 32\n",
            "epoch 122 batch 64\n",
            "epoch 123 batch 0\n",
            "epoch 123 batch 32\n",
            "epoch 123 batch 64\n",
            "epoch 124 batch 0\n",
            "epoch 124 batch 32\n",
            "epoch 124 batch 64\n",
            "epoch 125 batch 0\n",
            "epoch 125 batch 32\n",
            "epoch 125 batch 64\n",
            "Step 125 batch loss = 0.3826 trainning acc =0.870\n",
            "Model saved in path: /content/model/model125.ckpt\n",
            "(123,)\n",
            "0.8699186991869918\n",
            "(123,)\n",
            "epoch 126 batch 0\n",
            "epoch 126 batch 32\n",
            "epoch 126 batch 64\n",
            "epoch 127 batch 0\n",
            "epoch 127 batch 32\n",
            "epoch 127 batch 64\n",
            "epoch 128 batch 0\n",
            "epoch 128 batch 32\n",
            "epoch 128 batch 64\n",
            "epoch 129 batch 0\n",
            "epoch 129 batch 32\n",
            "epoch 129 batch 64\n",
            "epoch 130 batch 0\n",
            "epoch 130 batch 32\n",
            "epoch 130 batch 64\n",
            "Step 130 batch loss = 0.3211 trainning acc =0.902\n",
            "Model saved in path: /content/model/model130.ckpt\n",
            "(123,)\n",
            "0.9024390243902439\n",
            "(123,)\n",
            "epoch 131 batch 0\n",
            "epoch 131 batch 32\n",
            "epoch 131 batch 64\n",
            "epoch 132 batch 0\n",
            "epoch 132 batch 32\n",
            "epoch 132 batch 64\n",
            "epoch 133 batch 0\n",
            "epoch 133 batch 32\n",
            "epoch 133 batch 64\n",
            "epoch 134 batch 0\n",
            "epoch 134 batch 32\n",
            "epoch 134 batch 64\n",
            "epoch 135 batch 0\n",
            "epoch 135 batch 32\n",
            "epoch 135 batch 64\n",
            "Step 135 batch loss = 0.3517 trainning acc =0.886\n",
            "Model saved in path: /content/model/model135.ckpt\n",
            "(123,)\n",
            "0.8861788617886179\n",
            "(123,)\n",
            "epoch 136 batch 0\n",
            "epoch 136 batch 32\n",
            "epoch 136 batch 64\n",
            "epoch 137 batch 0\n",
            "epoch 137 batch 32\n",
            "epoch 137 batch 64\n",
            "epoch 138 batch 0\n",
            "epoch 138 batch 32\n",
            "epoch 138 batch 64\n",
            "epoch 139 batch 0\n",
            "epoch 139 batch 32\n",
            "epoch 139 batch 64\n",
            "epoch 140 batch 0\n",
            "epoch 140 batch 32\n",
            "epoch 140 batch 64\n",
            "Step 140 batch loss = 0.3764 trainning acc =0.870\n",
            "Model saved in path: /content/model/model140.ckpt\n",
            "(123,)\n",
            "0.8699186991869918\n",
            "(123,)\n",
            "epoch 141 batch 0\n",
            "epoch 141 batch 32\n",
            "epoch 141 batch 64\n",
            "epoch 142 batch 0\n",
            "epoch 142 batch 32\n",
            "epoch 142 batch 64\n",
            "epoch 143 batch 0\n",
            "epoch 143 batch 32\n",
            "epoch 143 batch 64\n",
            "epoch 144 batch 0\n",
            "epoch 144 batch 32\n",
            "epoch 144 batch 64\n",
            "epoch 145 batch 0\n",
            "epoch 145 batch 32\n",
            "epoch 145 batch 64\n",
            "Step 145 batch loss = 0.3730 trainning acc =0.870\n",
            "Model saved in path: /content/model/model145.ckpt\n",
            "(123,)\n",
            "0.8699186991869918\n",
            "(123,)\n",
            "epoch 146 batch 0\n",
            "epoch 146 batch 32\n",
            "epoch 146 batch 64\n",
            "epoch 147 batch 0\n",
            "epoch 147 batch 32\n",
            "epoch 147 batch 64\n",
            "epoch 148 batch 0\n",
            "epoch 148 batch 32\n",
            "epoch 148 batch 64\n",
            "epoch 149 batch 0\n",
            "epoch 149 batch 32\n",
            "epoch 149 batch 64\n",
            "Testing Acc: 0.86885244\n",
            "0.8688524590163934\n",
            "[1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1]\n",
            "[0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB27K6cz-bIx"
      },
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "tf.reset_default_graph()\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2 = 64\n",
        "dimention_1 = 26 # dimention of vocabulary\n",
        "dimention_2 = 7 # dimention of entities\n",
        "connect_dimention = 16 # dimention connect\n",
        "num_class = 2\n",
        "predict_keep_prop = 1\n",
        "\n",
        "  # tf Graph input\n",
        "X_11 = tf.placeholder('float',[None,dimention_1],name='X_11')\n",
        "X_21 = tf.placeholder('float',[None,dimention_2],name='X_21')\n",
        "Y1   = tf.placeholder('float',[None,num_class],name='Y1')\n",
        "\n",
        "weights = {\n",
        "    'concat_1': tf.Variable(tf.random_normal([dimention_1,connect_dimention]),name='concat_1'),\n",
        "    'concat_2': tf.Variable(tf.random_normal([dimention_2,connect_dimention]),name='concat_2'),\n",
        "    'h_1'     : tf.Variable(tf.random_normal([connect_dimention,n_hidden_1]),name='h_1'),\n",
        "    'h_2'     : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2]),name='h_2'),\n",
        "    'out'     : tf.Variable(tf.random_normal([n_hidden_2,num_class]),name='out')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b_1' : tf.Variable(tf.random_normal([n_hidden_1]),name='b_1'),\n",
        "    'b_2' : tf.Variable(tf.random_normal([n_hidden_2]),name='b_2'),\n",
        "    'out' : tf.Variable(tf.random_normal([num_class]),name='out')\n",
        "}\n",
        "def neural_net(x1,x2):\n",
        "  # Concat Feature\n",
        "  concat  = tf.add(tf.matmul(x1,weights['concat_1']),tf.matmul(x2,weights['concat_2']))\n",
        "  # hidden layer 1\n",
        "  layer_1 = tf.add(tf.matmul(concat,weights['h_1']),biases['b_1'])\n",
        "  layer_norm1 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_1 = layer_norm1(layer_1)\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  # hidden layer 2\n",
        "  layer_2 = tf.add(tf.matmul(layer_1,weights['h_2']),biases['b_2'])\n",
        "  layer_norm2 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_2 = layer_norm2(layer_2)\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  # drop_out\n",
        "  drop_out = tf.nn.dropout(layer_2, keep_prob)\n",
        "  # out layer\n",
        "  out_layer = tf.add(tf.matmul(drop_out,weights['out']),biases['out'])\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  layer_norma = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  out_layer = layer_norma(out_layer)\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  return out_layer\n",
        "\n",
        "def predict_raw_text(input):\n",
        "  # graph_meta = tf.train.import_meta_graph('/content/model/model95.ckpt.meta')\n",
        "  logits = neural_net(X_11, X_21)\n",
        "  probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  predict = tf.argmax(logits, 1)\n",
        "  vector1 = transform_document_to_vec(input)\n",
        "  vector2,slot = transform_entity_to_vec(input)\n",
        "  vector2 = vector2.reshape([1,7])\n",
        "  with tf.Session() as sess:\n",
        "    # graph_meta.restore(sess , tf.train.latest_checkpoint('/content/model'))\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, '/content/model/model145.ckpt')\n",
        "    pred , prop ,log = sess.run([predict,probabilities,logits],feed_dict={X_11: vector1,\n",
        "                                       X_21: vector2})\n",
        "  \n",
        "  return pred[0], prop\n",
        "\n",
        "# print(predict_raw_text('Bán gấp nhà Văn Điển 5 tầng ô tô đỗ gần chỉ 2,7 tỷ ... + Nhà mới đẹp Văn Điển ở ngay , ô tô đỗ gần , công năng đầy đủ cho 1 hộ gia đình ở : 1 khách , bếp , 2 ngủ , 3wc , phòng thờ , sân phơi . Có thể lên thêm 2 tầng thoải mái ... + Nhà Văn Điển gần rất nhiều tiện ích : chợ , trung tâm thương mại , bệnh viện , trung tâm thể dục thể thao , huyện ủy thanh trì ... + Khu vực Thanh Trì sắp lên Quận giá trị bất động sản ngày một tang , khách mua năm sbawts tình hình mua đợt này dịch giá có bớt cho ai thiện chí ... + Khu vực Thanh trì lên trung tâm thành phố rất gần chỉ 15 phút , đi các quận rất thuận tiện , về quê qua bến xe nước ngầm chỉ 2 phút ... + Nhà đẹp sổ vuông nở hậu ... + Liên hệ Mrs Thúy : 0965 - 2535 - 83'))\n",
        "# 1/0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFuJ0JJsTTl",
        "outputId": "4fb55d61-ba3c-4bd4-f93a-7a70c0c125af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(predict_raw_text(data[1001]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model/model145.ckpt\n",
            "(1, array([[0.16312231, 0.83687776]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rNiwlHvVgq",
        "outputId": "92c89a39-b7f1-4f33-ebd7-fff8691327e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy.special import softmax\n",
        "m = softmax([[230   , 1000]])\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L25DzbJjHKl2"
      },
      "source": [
        "kaggle datasets download -d thanhlong1997/word2vec-vn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAxiLT0UMSy5",
        "outputId": "544a096f-b1e3-4ced-ea2b-7736565a8b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgNhMVfKutUy",
        "outputId": "f78b52d9-7b21-4f91-a76c-9441f27042e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(data[1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '* Hàng cực hot hoàn thiện đẹp trước tết về ở luôn chỉ 1 căn duy nhất . LH xem nhà : A Thủy 0939965555/0379500000 ... (Tặng 2 phiếu bốc thăm trúng xe Vision trị giá 40tr khi mua nhà của cty chúng tôi) ... * Nhà Phú Lãm xây 3 tầng 35m2 ngõ thông ô tô đỗ 10m đã hoàn thiện giá chỉ 1,63 tỷ (ảnh thật 100%) ... Thiết kế gồm : . Tầng 1 : Phòng khách , bếp , 1 nhà vệ sinh ... Tầng 2 : 2 phòng ngủ , 1 vệ sinh ... Tầng 3 : 1 phòng thờ (phòng ngủ), 1 sân phơi rộng thoáng ... Thiết kế và xây dựng do kiến trúc sư tính toán tối đa công năng sử dụng và rất tiện ích ... Nhà được xây có móng riêng , cột riêng , tường riêng . Đảm bảo an toàn và sửa chữa . Có thể xây thêm tầng 4,5 thoải mái ... Sổ đỏ và giấy phép xây dựng đầy đủ ... * Nội thất cao cấp đầy đủ nội thất cơ bản về chỉ việc ở như hệ thống điện nước , tủ bếp , vệ sinh , trần thạch cao .. ... * Vị trí và tiện ích là 2 yếu tố chính mà mỗi người mua nhà đều quan tâm nhất thì ở đây đáp ứng được đầy đủ các yêu cầu đó ... Nhà gần Quốc lộ 21B , gần chợ , trường học , UBND phường , nhà văn hóa , khu dân cư văn minh , an toàn ... Đường vào rộng 3m , chỗ để ô tô cách nhà 30m ... Kích thước khá đẹp : 3,75mx9,08m ... Giá : 1,63 tỷ (bao toàn bộ phí sang tên cho người mua) ... Liên hệ ngay : 0939965555/0379500000 a Thủy xem nhà ... Hỗ trợ làm KT3 và thủ tục nhập học cho các cháu .', 'labels': [[84, 90, 'contact_name'], [91, 112, 'contact_mobile'], [173, 176, 'type'], [210, 217, 'location'], [222, 228, 'floor'], [229, 233, 'size'], [278, 285, 'price'], [323, 329, 'number_floor'], [332, 343, 'number_livingroom'], [346, 349, 'number_kitchen'], [352, 365, 'number_dressroom'], [370, 376, 'number_floor'], [379, 390, 'number_bedroom'], [393, 402, 'number_dressroom'], [407, 413, 'number_floor'], [416, 427, 'san_phoi_thuong'], [441, 451, 'san_phoi_thuong'], [661, 669, 'number_floor'], [684, 689, 'legal'], [897, 900, 'type'], [980, 991, 'near_places'], [1094, 1096, 'size_mat_ngo'], [1149, 1160, 'size_mat_ngo'], [1171, 1204, 'price'], [1215, 1218, 'type'], [1239, 1260, 'contact_mobile'], [1261, 1267, 'contact_name']]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJsj6EgjCWh"
      },
      "source": [
        "\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    tf.reset_default_graph()\n",
        "    self.n_hidden_1 = 256\n",
        "    self.n_hidden_2 = 64\n",
        "    self.dimention_1 = 26 # dimention of vocabulary\n",
        "    self.dimention_2 = 7 # dimention of entities\n",
        "    self.connect_dimention = 16 # dimention connect\n",
        "    self.num_class = 2\n",
        "    self.keep_prob = 1\n",
        "    \n",
        "\n",
        "      # tf Graph input\n",
        "    self.X_11 = tf.placeholder('float',[None,self.dimention_1],name='X_11')\n",
        "    self.X_21 = tf.placeholder('float',[None,self.dimention_2],name='X_21')\n",
        "    self.Y1   = tf.placeholder('float',[None,self.num_class],name='Y1')\n",
        "\n",
        "    self.weights = {\n",
        "        'concat_1': tf.Variable(tf.random_normal([self.dimention_1,self.connect_dimention]),name='concat_1'),\n",
        "        'concat_2': tf.Variable(tf.random_normal([self.dimention_2,self.connect_dimention]),name='concat_2'),\n",
        "        'h_1'     : tf.Variable(tf.random_normal([self.connect_dimention,self.n_hidden_1]),name='h_1'),\n",
        "        'h_2'     : tf.Variable(tf.random_normal([self.n_hidden_1,self.n_hidden_2]),name='h_2'),\n",
        "        'out'     : tf.Variable(tf.random_normal([self.n_hidden_2,self.num_class]),name='out')\n",
        "    }\n",
        "\n",
        "    self.biases = {\n",
        "        'b_1' : tf.Variable(tf.random_normal([self.n_hidden_1]),name='b_1'),\n",
        "        'b_2' : tf.Variable(tf.random_normal([self.n_hidden_2]),name='b_2'),\n",
        "        'out' : tf.Variable(tf.random_normal([self.num_class]),name='out')\n",
        "    }\n",
        "    self.predict, self.prob = self.neural_net(self.X_11,self.X_21)\n",
        "    self.initialize_and_restore_session()\n",
        "\n",
        "  def neural_net(self,x1,x2):\n",
        "    # Concat Feature\n",
        "    concat  = tf.add(tf.matmul(x1,self.weights['concat_1']),tf.matmul(x2,self.weights['concat_2']))\n",
        "    # hidden layer 1\n",
        "    layer_1 = tf.add(tf.matmul(concat,self.weights['h_1']),self.biases['b_1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    # hidden layer 2\n",
        "    layer_2 = tf.add(tf.matmul(layer_1,self.weights['h_2']),self.biases['b_2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # drop out\n",
        "    drop_out = tf.nn.dropout(layer_2,self.keep_prob)\n",
        "    # out layer\n",
        "    out_layer = tf.add(tf.matmul(drop_out,self.weights['out']),self.biases['out'])\n",
        "    probabilities = tf.nn.softmax(out_layer, axis=-1)\n",
        "    return out_layer , probabilities\n",
        "\n",
        "  def initialize_and_restore_session(self):\n",
        "        \"\"\"Defines self.sess and initialize the variables\"\"\"\n",
        "        print(\"Initializing tf session\")\n",
        "        # config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, device_count={'GPU': 0})\n",
        "        # config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        self.saver = tf.train.Saver()\n",
        "        self.saver.restore(self.sess, '/content/model/model145.ckpt')\n",
        "        print(\"Complete restore model from \")\n",
        "\n",
        "  def predict_raw_text(self,input):\n",
        "    # print(input['text'])\n",
        "    # text = input['text']\n",
        "    # graph_meta = tf.train.import_meta_graph('/content/model/model95.ckpt.meta')\n",
        "    predict = tf.argmax(self.predict, 1)\n",
        "    vector1 = transform_document_to_vec(input)\n",
        "    vector2,slot = transform_entity_to_vec(input)\n",
        "    vector2 = vector2.reshape([1,7])\n",
        "    pred , prob = self.sess.run([predict,self.prob],feed_dict={self.X_11: vector1,\n",
        "                                        self.X_21: vector2})\n",
        "    print(pred , prob)\n",
        "    return pred\n",
        "\n",
        "\n",
        "# print(predict_raw_text('Bán gấp nhà Văn Điển 5 tầng ô tô đỗ gần chỉ 2,7 tỷ ... + Nhà mới đẹp Văn Điển ở ngay , ô tô đỗ gần , công năng đầy đủ cho 1 hộ gia đình ở : 1 khách , bếp , 2 ngủ , 3wc , phòng thờ , sân phơi . Có thể lên thêm 2 tầng thoải mái ... + Nhà Văn Điển gần rất nhiều tiện ích : chợ , trung tâm thương mại , bệnh viện , trung tâm thể dục thể thao , huyện ủy thanh trì ... + Khu vực Thanh Trì sắp lên Quận giá trị bất động sản ngày một tang , khách mua năm sbawts tình hình mua đợt này dịch giá có bớt cho ai thiện chí ... + Khu vực Thanh trì lên trung tâm thành phố rất gần chỉ 15 phút , đi các quận rất thuận tiện , về quê qua bến xe nước ngầm chỉ 2 phút ... + Nhà đẹp sổ vuông nở hậu ... + Liên hệ Mrs Thúy : 0965 - 2535 - 83'))\n",
        "# 1/0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl2xfdBVmYyA",
        "outputId": "cedf55c6-dd65-4d1e-bd16-df011eac9ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = Model()\n",
        "print(model.predict_raw_text(data[1002]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing tf session\n",
            "INFO:tensorflow:Restoring parameters from /content/model/model145.ckpt\n",
            "Complete restore model from \n",
            "[0] [[1. 0.]]\n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-lPG9P5PBkn",
        "outputId": "de88f1ea-a636-4e06-b308-833e52f3881f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(transform_entity_to_vec(data[1001]))\n",
        "print(transform_entity_to_vec(data[1002]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([1., 0., 0., 0., 0., 0., 1.]), {'house_sizes': {'use_area': 140.0, 'total_land_area': 35.0, 'contruction_area': 35.0}, 'house_description': {'floor': 4.0, 'mat_tien': '', 'size_mat_ngo': '', 'number_livingroom': '', 'number_kitchen': '', 'number_dressroom': '', 'number_bedroom': '3 phòng ngủ'}, 'land_description': {}, 'price': '1,53 tỷ (Có thương lượng và bao phí sang tên)', 'house_locate': {'near_places': 'chợ Xốm The Vesta chợ Xốm đường Quang Lãm - Phường Phú Lãm - Quận Hà Đông - TP . Hà Nội ngã 3 Ba La ', 'location': 'Quang Lãm '}, 'contact': {'contact_mobile': '0866766916', 'email': ''}})\n",
            "(array([1., 0., 1., 1., 1., 1., 1.]), {'house_sizes': {'use_area': 144.0, 'total_land_area': 36.0, 'contruction_area': 36.0}, 'house_description': {'floor': 4.0, 'mat_tien': '', 'size_mat_ngo': 'gần 3m', 'number_livingroom': 'Phòng khách', 'number_kitchen': 'bếp', 'number_dressroom': 'vệ sinh', 'number_bedroom': 'Mỗi tầng'}, 'land_description': {}, 'price': '1,52 tỷ thương lượng nhẹ', 'house_locate': {'near_places': '', 'location': ''}, 'contact': {'contact_mobile': '0345184078 ... Thông', 'email': ''}})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJFyE70Q0_k"
      },
      "source": [
        "import json\n",
        "with open('/content/result4700.json','r',encoding='utf-8') as file:\n",
        "  data_test = json.load(file)\n",
        "result = []\n",
        "for index in range(1000,1100):\n",
        "  result.append(predict_raw_text(data[index]))\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYodTGT5VbkZ",
        "outputId": "879a6b9b-7334-41d3-9b04-382865ea08f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(result[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcbp_Rl-aly",
        "outputId": "16bc5485-fc0a-4628-da26-f9816508c343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for index in range(len(result)):\n",
        "  if result[index] == 1:\n",
        "    print(index+1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1018\n",
            "1049\n",
            "1061\n",
            "1067\n",
            "1069\n",
            "1073\n",
            "1085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrVjqfZN5ozQ"
      },
      "source": [
        "query = pd.read_csv('qq4.csv',encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXZq1i3s6i36",
        "outputId": "de3dd410-c111-4f04-9cb8-40bb653dcc0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "query.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>360 giai phong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4s linh dong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ascent lakeside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ban an phu shop villa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ban biet thu a chau vung tau</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                             0\n",
              "0           0               360 giai phong \n",
              "1           1                  4s linh dong\n",
              "2           2               ascent lakeside\n",
              "3           3         ban an phu shop villa\n",
              "4           4  ban biet thu a chau vung tau"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qK8Ey5Y_oTS"
      },
      "source": [
        "import re\n",
        "list_index = []\n",
        "for index in (query.index):\n",
        "  if re.search('chung cu|chung cư|nhà|nha|biet thu|biệt thự|liền kề|lien ke|đất|dat|căn hộ|can ho|khach san|cua hang|phong tro|mat bang',query['0'][index]):\n",
        "    list_index.append(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl3F9JzIAavT",
        "outputId": "069e4139-f44f-4685-d84d-10b0d5a2f1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(list_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbTR_twbC3wu",
        "outputId": "dbb024f0-41a3-4f47-b33f-812680d27991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index in query.index :\n",
        "  if index not in list_index:\n",
        "    print(query['0'][index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360 giai phong \n",
            "4s linh dong\n",
            "ascent lakeside\n",
            "ban an phu shop villa\n",
            "ban can shophouse vinhomes smart city dai mo\n",
            "ban dao tai ho thac ba yen bai\n",
            "ban homestay da lat\n",
            "ban ki ot hh1hh2 linh dam hoang mai\n",
            "ban kiot gia re quang nam\n",
            "ban penthouse quan 7 gia re\n",
            "ban san thuong mai du an an binh city\n",
            "ban sarimi 3pn\n",
            "ban shophouse geleximco le trong tan\n",
            "ban shophouse hc golden city\n",
            "ban shophouse kien hung ha dong\n",
            "ban trang trai duong lang hoa lac\n",
            "bat dong san\n",
            "bat dong san .com\n",
            "bat dong san .com\n",
            "bat dong san an giang\n",
            "bat dong san ben tre\n",
            "bat dong san bien hoa\n",
            "bat dong san cham com\n",
            "bat dong san dien khanh\n",
            "bat dong san dong anh\n",
            "bat dong san hai phong\n",
            "bat dong san hoi an\n",
            "bat dong san tay ninh\n",
            "bat dong san thai binh\n",
            "bat dong san thanh oai ha noi\n",
            "bat dong san vinh phuc\n",
            "bat dong san. vn\n",
            "bat dong san.com.vn\n",
            "batdongsan\n",
            "batdongsan da nang\n",
            "batdongsan. com.vn\n",
            "batdongsan.com.vn apk\n",
            "batdongsan.vn\n",
            "batdongsandanang\n",
            "bau bang\n",
            "bds.com\n",
            "binh duong\n",
            "C14 kim lien\n",
            "Can ho c14 kim lien\n",
            "celadon city\n",
            "chdv\n",
            "cho thue phong studio quan 7\n",
            "Chung cu giai viet\n",
            "cotec phu xuan\n",
            "d le roi soleil   quang an  ha noi\n",
            "de capella\n",
            "du an diamond riverside\n",
            "du an dragon city bau bang\n",
            "du an ocean dunes\n",
            "du an tuong binh hiep\n",
            "duong nguyen cong binh my tho\n",
            "duong u ghe kp2 phuong tam phu quan thu duc\n",
            "eco xuan lai thieu\n",
            "ehome 4\n",
            "ehome 5\n",
            "felisa riverside\n",
            "felix home\n",
            "goldmark city\n",
            "hc golden city\n",
            "homyland 2\n",
            "Hong tien long bien\n",
            "ia20 ciputra\n",
            "imperia garden\n",
            "khanh hoa\n",
            "khu dan cu dai loi quoc lo 13\n",
            "kingsway tower\n",
            "la astoria quan 2\n",
            "la3 nguyen duy trinh\n",
            "lancaster nui truc\n",
            "marine city\n",
            "mega city 2\n",
            "mega village\n",
            "moonlight park view\n",
            "muabanbatdongsan\n",
            "nam khang residence\n",
            "new dong hoi gosabe city quang binh\n",
            "novaworld phan thiet\n",
            "parcspring\n",
            "penhouseneco green\n",
            "phu cat city\n",
            "phu thinh green prak\n",
            "phuc yen 3\n",
            "rivera park 69 vu trong phung\n",
            "ruby city ct3\n",
            "safira\n",
            "saigon riverpark\n",
            "saigon village\n",
            "san bat dong san\n",
            "sang nhuong co so san xuat nuoc uong tinh khiet tphcm\n",
            "sang nhuong tiem dien nuoc\n",
            "sang quan cafe\n",
            "sang quan cafe quan phu nhuan\n",
            "sang quan cafe tphcm\n",
            "sang quan khu ten lua\n",
            "sealinks\n",
            "sunwah pearl\n",
            "the k park\n",
            "the sun avenue\n",
            "the viva city\n",
            "thi xa lagi  binh thuan\n",
            "Thien duong bao son\n",
            "thong tin bat dong san\n",
            "tht new city\n",
            "thu thiem dragon\n",
            "tin bat dong san\n",
            "tin tuc bat dong san\n",
            "tin tuc bat dong san tp hcm\n",
            "tinh hinh bat dong san hien nay\n",
            "vinhomes symphony\n",
            "xa dien toan  huyen dien khanh  khanh hoa\n",
            "yen phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4pH4SLhE3Ew"
      },
      "source": [
        "import re\n",
        "class classifi_property(object):\n",
        "  def __init__(self):\n",
        "    pass \n",
        "  \n",
        "  def rule_check_type(self,input):\n",
        "    input = input.lower()\n",
        "    if re.search('chung cu|chung cư|can ho|căn hộ',input):\n",
        "      return 'Apartment'\n",
        "    if re.search('nhà|nha|lien ke|liền kề', input):\n",
        "      return 'House'\n",
        "    if re.search('biet thu|biệt thự|villa', input):\n",
        "      return 'Villa'\n",
        "    if re.search('khach san|khách sạn', input):\n",
        "      return 'Hotel'\n",
        "    if re.search('cửa hàng|cua hang|quan|shop', input):\n",
        "      return 'Shop'\n",
        "    if re.search('đất|dat|mặt bằng|mat bang', input):\n",
        "      return 'Land'\n",
        "    return 'Unknow'\n",
        "  \n",
        "  def rule_check_intent(self,input):\n",
        "    input = input.lower()\n",
        "    if re.search('ban|bán|sang nhuong|sang nhượng',input):\n",
        "      return 'Sell'\n",
        "    if re.search('mua',input):\n",
        "      return 'Buy'\n",
        "    if re.search('thue|thuê',input):\n",
        "      return 'Rent'\n",
        "    return 'Unknow'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1chQ0KEoIJHt",
        "outputId": "d54b90b8-2a48-4a11-aef4-14f29dfc4e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = classifi_property()\n",
        "for index in query.index:\n",
        "  if model.rule_check_type(query['0'][index]) == 'Unknow':\n",
        "    print(query['0'][index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360 giai phong \n",
            "4s linh dong\n",
            "ascent lakeside\n",
            "ban dao tai ho thac ba yen bai\n",
            "ban homestay da lat\n",
            "ban ki ot hh1hh2 linh dam hoang mai\n",
            "ban san thuong mai du an an binh city\n",
            "ban sarimi 3pn\n",
            "ban trang trai duong lang hoa lac\n",
            "bat dong san\n",
            "bat dong san .com\n",
            "bat dong san .com\n",
            "bat dong san an giang\n",
            "bat dong san ben tre\n",
            "bat dong san bien hoa\n",
            "bat dong san cham com\n",
            "bat dong san dien khanh\n",
            "bat dong san dong anh\n",
            "bat dong san hai phong\n",
            "bat dong san hoi an\n",
            "bat dong san tay ninh\n",
            "bat dong san thai binh\n",
            "bat dong san thanh oai ha noi\n",
            "bat dong san vinh phuc\n",
            "bat dong san. vn\n",
            "bat dong san.com.vn\n",
            "batdongsan\n",
            "batdongsan da nang\n",
            "batdongsan. com.vn\n",
            "batdongsan.com.vn apk\n",
            "batdongsan.vn\n",
            "batdongsandanang\n",
            "bau bang\n",
            "bds.com\n",
            "binh duong\n",
            "C14 kim lien\n",
            "celadon city\n",
            "chdv\n",
            "cho thue phong tro gan etown\n",
            "cho thue phong tro gan etown cong hoa\n",
            "cho thue phong tro gan kinh te quoc dan\n",
            "cho thue phong tro gan truong dai hoc bach khoa lien chieu\n",
            "cho thue phong tro gia re\n",
            "cotec phu xuan\n",
            "de capella\n",
            "du an diamond riverside\n",
            "du an dragon city bau bang\n",
            "du an ocean dunes\n",
            "du an tuong binh hiep\n",
            "duong nguyen cong binh my tho\n",
            "eco xuan lai thieu\n",
            "ehome 4\n",
            "ehome 5\n",
            "felisa riverside\n",
            "felix home\n",
            "goldmark city\n",
            "hc golden city\n",
            "homyland 2\n",
            "Hong tien long bien\n",
            "ia20 ciputra\n",
            "imperia garden\n",
            "khanh hoa\n",
            "khu dan cu dai loi quoc lo 13\n",
            "kingsway tower\n",
            "la3 nguyen duy trinh\n",
            "lancaster nui truc\n",
            "marine city\n",
            "mega city 2\n",
            "moonlight park view\n",
            "muabanbatdongsan\n",
            "nam khang residence\n",
            "novaworld phan thiet\n",
            "parcspring\n",
            "penhouseneco green\n",
            "phong tro gan cho bac my an da nang\n",
            "phong tro thuan an binh duong\n",
            "phu cat city\n",
            "phu thinh green prak\n",
            "phuc yen 3\n",
            "rivera park 69 vu trong phung\n",
            "ruby city ct3\n",
            "safira\n",
            "saigon riverpark\n",
            "san bat dong san\n",
            "sang nhuong co so san xuat nuoc uong tinh khiet tphcm\n",
            "sang nhuong tiem dien nuoc\n",
            "sealinks\n",
            "sunwah pearl\n",
            "the k park\n",
            "the sun avenue\n",
            "the viva city\n",
            "thi xa lagi  binh thuan\n",
            "Thien duong bao son\n",
            "thong tin bat dong san\n",
            "tht new city\n",
            "thu thiem dragon\n",
            "tin bat dong san\n",
            "tin tuc bat dong san\n",
            "tin tuc bat dong san tp hcm\n",
            "tinh hinh bat dong san hien nay\n",
            "vinhomes symphony\n",
            "xa dien toan  huyen dien khanh  khanh hoa\n",
            "yen phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACjYHXuIK53d",
        "outputId": "f6169b90-b0ed-45ea-bf5a-cbcf8d5a1f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for index in query.index:\n",
        "  if model.rule_check_intent(query['0'][index]) == 'Unknow':\n",
        "    print(query['0'][index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "360 giai phong \n",
            "4s linh dong\n",
            "ascent lakeside\n",
            "bat dong san\n",
            "bat dong san .com\n",
            "bat dong san .com\n",
            "bat dong san an giang\n",
            "bat dong san ben tre\n",
            "bat dong san bien hoa\n",
            "bat dong san cham com\n",
            "bat dong san dien khanh\n",
            "bat dong san dong anh\n",
            "bat dong san hai phong\n",
            "bat dong san hoi an\n",
            "bat dong san tay ninh\n",
            "bat dong san thai binh\n",
            "bat dong san thanh oai ha noi\n",
            "bat dong san vinh phuc\n",
            "bat dong san. vn\n",
            "bat dong san.com.vn\n",
            "batdongsan\n",
            "batdongsan da nang\n",
            "batdongsan nha trang\n",
            "batdongsan. com.vn\n",
            "batdongsan.com.vn apk\n",
            "batdongsan.vn\n",
            "batdongsandanang\n",
            "bds.com\n",
            "biet thu ecopark\n",
            "biet thu nam an khanh\n",
            "biet thu vinhomes riverside\n",
            "binh duong\n",
            "C14 kim lien\n",
            "can ho binh duong\n",
            "Can ho c14 kim lien\n",
            "can ho centana thu thiem\n",
            "can ho cityland go vap\n",
            "can ho feliz en vista\n",
            "can ho gold view\n",
            "can ho hoang anh thanh binh\n",
            "can ho idico tan phu\n",
            "can ho moonlight thu duc\n",
            "can ho opal garden\n",
            "can ho pegasuite\n",
            "can ho quan 10\n",
            "can ho quan 4\n",
            "can ho quan 8\n",
            "can ho sky 9\n",
            "can ho sunrise city\n",
            "celadon city\n",
            "chdv\n",
            "chung cu 1050 chu van an\n",
            "chung cu 155 nguyen chi thanh\n",
            "chung cu 43 pham van dong\n",
            "chung cu 60 hoang quoc viet\n",
            "chung cu 789 my dinh\n",
            "chung cu 789 xuan dinh\n",
            "chung cu 8x plus\n",
            "chung cu a10 nam trung yen\n",
            "chung cu an loc\n",
            "chung cu an phu dong\n",
            "chung cu b1 truong sa\n",
            "chung cu bac ninh\n",
            "chung cu bo cong an quan 2\n",
            "chung cu cau giay\n",
            "chung cu celadon\n",
            "chung cu cityland go vap\n",
            "chung cu cuu long\n",
            "chung cu dang xa\n",
            "chung cu dat phuong nam\n",
            "chung cu dinh cong\n",
            "chung cu duc khai quan 2\n",
            "chung cu flora anh dao\n",
            "Chung cu giai viet\n",
            "chung cu green bay\n",
            "chung cu ha do quan 12\n",
            "chung cu harmona\n",
            "chung cu hateco xuan phuong\n",
            "chung cu hh linh dam\n",
            "chung cu hiep thanh 3\n",
            "chung cu him lam quan 7\n",
            "chung cu home city\n",
            "chung cu iris garden\n",
            "chung cu jamila\n",
            "chung cu le thanh ma lo\n",
            "chung cu linh trung\n",
            "chung cu lotus\n",
            "chung cu ly thuong kiet\n",
            "chung cu man thien\n",
            "chung cu mini danh cho nguoi nuoc ngoai\n",
            "chung cu mini gan kinh te quoc dan\n",
            "chung cu moonlight park view\n",
            "chung cu my phuc\n",
            "chung cu nam trung yen\n",
            "chung cu new city\n",
            "chung cu ngo tat to\n",
            "chung cu ngoc lan\n",
            "chung cu nguyen ngoc phuong\n",
            "chung cu opal garden\n",
            "chung cu petroland\n",
            "chung cu ph nha trang\n",
            "chung cu phu gia hung\n",
            "chung cu phu thanh\n",
            "chung cu phuc yen\n",
            "chung cu quan 6\n",
            "chung cu quan 7\n",
            "chung cu quan binh thanh\n",
            "chung cu royal city\n",
            "chung cu saigonres\n",
            "chung cu season avenue\n",
            "chung cu tan binh\n",
            "chung cu tan viet\n",
            "chung cu tay thanh\n",
            "chung cu the pride\n",
            "chung cu thong tan xa\n",
            "chung cu thu thiem garden\n",
            "chung cu time city\n",
            "chung cu van quan\n",
            "chung cu vien 103\n",
            "chung cu vung tau\n",
            "chung cu xuan mai complex\n",
            "co nha quan 8 2019\n",
            "cotec phu xuan\n",
            "d le roi soleil   quang an  ha noi\n",
            "dat an vien\n",
            "dat bac ninh\n",
            "dat ben luc\n",
            "dat chon thanh\n",
            "dat dan phuong\n",
            "dat dau gia mau luong\n",
            "dat di an\n",
            "dat dich vu dong mai\n",
            "dat dich vu phu luong\n",
            "dat dich vu van canh\n",
            "dat dien khanh\n",
            "dat duc hoa\n",
            "dat hoa lien\n",
            "dat hoa lien 5\n",
            "dat hoa tien\n",
            "dat hoa xuan\n",
            "dat hoa xuan\n",
            "dat hoa xuan da nang\n",
            "dat lai thieu\n",
            "dat long khanh\n",
            "dat my phuoc 3\n",
            "dat nam luxury\n",
            "dat nam viet a\n",
            "dat nen di an\n",
            "dat nen gaia\n",
            "dat nen long hung\n",
            "dat nhi binh\n",
            "dat phuoc dong\n",
            "dat soc son\n",
            "dat song trau\n",
            "dat thanh ha\n",
            "dat thanh tri\n",
            "dat thu dau mot\n",
            "dat thu duc\n",
            "dat vinh phu 1\n",
            "de capella\n",
            "du an diamond riverside\n",
            "du an ocean dunes\n",
            "du an tuong binh hiep\n",
            "duong nguyen cong binh my tho\n",
            "duong u ghe kp2 phuong tam phu quan thu duc\n",
            "eco xuan lai thieu\n",
            "ehome 4\n",
            "ehome 5\n",
            "felisa riverside\n",
            "felix home\n",
            "gia dat long khanh\n",
            "goldmark city\n",
            "hc golden city\n",
            "homyland 2\n",
            "Hong tien long bien\n",
            "ia20 ciputra\n",
            "imperia garden\n",
            "khanh hoa\n",
            "khu biet thu nam phu\n",
            "khu dan cu dai loi quoc lo 13\n",
            "kingsway tower\n",
            "la astoria quan 2\n",
            "la3 nguyen duy trinh\n",
            "lam nha nam 37 tuoi\n",
            "lancaster nui truc\n",
            "lien ke dai kim\n",
            "lien ke nam 32\n",
            "lien ke thanh ha\n",
            "lien ke tong cuc 5 tan trieu\n",
            "lien ke van phu\n",
            "marine city\n",
            "mega city 2\n",
            "mega village\n",
            "moonlight park view\n",
            "nam khang residence\n",
            "new dong hoi gosabe city quang binh\n",
            "nha dat bac lieu\n",
            "nha dat bao loc\n",
            "nha dat ben tre\n",
            "nha dat chinh chu ha noi\n",
            "nha dat dien khanh\n",
            "nha dat ha dong\n",
            "nha dat kien an\n",
            "nha dat long khanh\n",
            "nha dat nha trang\n",
            "nha dat soc son\n",
            "nha dat thu duc\n",
            "nha duong quang ham go vap\n",
            "nha long an\n",
            "nha mat tien quan 1\n",
            "nha mat tien quan 10\n",
            "nha mat tien quan 3\n",
            "nha tro quan 8\n",
            "nhuong cua hang nail\n",
            "novaworld phan thiet\n",
            "parcspring\n",
            "penhouseneco green\n",
            "phong tro gan cho bac my an da nang\n",
            "phong tro thuan an binh duong\n",
            "phu cat city\n",
            "phu thinh green prak\n",
            "phuc yen 3\n",
            "rivera park 69 vu trong phung\n",
            "ruby city ct3\n",
            "safira\n",
            "saigon riverpark\n",
            "saigon village\n",
            "san bat dong san\n",
            "sang quan cafe\n",
            "sang quan cafe quan phu nhuan\n",
            "sang quan cafe tphcm\n",
            "sang quan khu ten lua\n",
            "sealinks\n",
            "sunwah pearl\n",
            "the k park\n",
            "the sun avenue\n",
            "the viva city\n",
            "thi xa lagi  binh thuan\n",
            "Thien duong bao son\n",
            "thong tin bat dong san\n",
            "tht new city\n",
            "thu thiem dragon\n",
            "tim phong tro quan 10 duong su van hanh\n",
            "tin bat dong san\n",
            "tin tuc bat dong san\n",
            "tin tuc bat dong san tp hcm\n",
            "tinh hinh bat dong san hien nay\n",
            "vinhomes symphony\n",
            "xa dien toan  huyen dien khanh  khanh hoa\n",
            "yen phong\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qs6LU0jIvoQ",
        "outputId": "35ed9e89-ef7a-4765-c089-ee15f42a74e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = classifi_property(query['0'][6])\n",
        "print(a.rule_check)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method classifi_property.rule_check of <__main__.classifi_property object at 0x7fcdf741c240>>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}