{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwsn/+8UaEh/x/o1hPUgq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "908c6fef715d40ee8d7bb78f82613c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c681a216eca548d99660e238f2effa58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12912f6b19554f429285560be96cf976",
              "IPY_MODEL_cb10a740e8cc4d3a98dcd9bb7f43ec21"
            ]
          }
        },
        "c681a216eca548d99660e238f2effa58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12912f6b19554f429285560be96cf976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_329bfa4898704015a63cf8180f208ca0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1409e61867954f6b9731212bcf97329c"
          }
        },
        "cb10a740e8cc4d3a98dcd9bb7f43ec21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_044b1f28fef5439c9488cb805d3f6758",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/557 [00:00&lt;00:00, 1.97kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5da01728072a4208bff5f674d5de5064"
          }
        },
        "329bfa4898704015a63cf8180f208ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1409e61867954f6b9731212bcf97329c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "044b1f28fef5439c9488cb805d3f6758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5da01728072a4208bff5f674d5de5064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73db3e25f26449119cadc9b2eb08c09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8ee4701403c4933b345663ece140915",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0182f666d78a4f7d812b1a0fa6eb91ab",
              "IPY_MODEL_07b8dd95bdd84d5890c6a1278866be90"
            ]
          }
        },
        "a8ee4701403c4933b345663ece140915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0182f666d78a4f7d812b1a0fa6eb91ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4ea66dbc5574a708d9957267fe82f20",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 542923308,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 542923308,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7093c5ab0ba45e7805030e9ba3b04f6"
          }
        },
        "07b8dd95bdd84d5890c6a1278866be90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63639ed1f1ee42d6a654e5493f67848b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 543M/543M [00:09&lt;00:00, 58.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16734bba3c1944aabab30d5a7f09aa4d"
          }
        },
        "d4ea66dbc5574a708d9957267fe82f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7093c5ab0ba45e7805030e9ba3b04f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63639ed1f1ee42d6a654e5493f67848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16734bba3c1944aabab30d5a7f09aa4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2955c6100dda41beae27ab084139e1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c693fd22dbd4cdf8e57b055a91382de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc4c490f48c94585be0d33a473de5822",
              "IPY_MODEL_d8cdc6e2b8fc4c819a1eb475c15abc2a"
            ]
          }
        },
        "0c693fd22dbd4cdf8e57b055a91382de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc4c490f48c94585be0d33a473de5822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed7284585c194b61b36854ddefe47ad1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6115a0dd1f264ea0895ea4b8ce9ade2b"
          }
        },
        "d8cdc6e2b8fc4c819a1eb475c15abc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f695b875b66e42e2816111c6e393117e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 895k/895k [00:00&lt;00:00, 1.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_166aa820d59e41ff8f2c8d4303813f52"
          }
        },
        "ed7284585c194b61b36854ddefe47ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6115a0dd1f264ea0895ea4b8ce9ade2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f695b875b66e42e2816111c6e393117e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "166aa820d59e41ff8f2c8d4303813f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "885e2fdc88e54406afe3c2a241899614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b53d5cd5b25c46fe8fe3313aab47f15a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_634615d0abeb4d899f0f3d9af72f66dc",
              "IPY_MODEL_9bf585ad7993415c9fad9ab306fae675"
            ]
          }
        },
        "b53d5cd5b25c46fe8fe3313aab47f15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "634615d0abeb4d899f0f3d9af72f66dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33aa7e0f54914a59874623eb3b591b49",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_771fb73a47394b7da42398d85d2c93cc"
          }
        },
        "9bf585ad7993415c9fad9ab306fae675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e78112261cd347ed9794111d4a331ebb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.14M/1.14M [00:00&lt;00:00, 5.50MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99d26586f8a84e5fbc8c5f4104395c47"
          }
        },
        "33aa7e0f54914a59874623eb3b591b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "771fb73a47394b7da42398d85d2c93cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e78112261cd347ed9794111d4a331ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99d26586f8a84e5fbc8c5f4104395c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhlong1997/100-nlp-papers/blob/master/mlp_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz79TpKNA6Ej",
        "outputId": "74d42f09-1ce8-49b4-e84f-78237e3ab9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-13 08:11:37--  https://s3.amazonaws.com/models.huggingface.co/bert/vinai/phobert-base/vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.141.206\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.141.206|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 895321 (874K) [text/plain]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 874.34K   966KB/s    in 0.9s    \n",
            "\n",
            "2020-10-13 08:11:38 (966 KB/s) - ‘vocab.txt’ saved [895321/895321]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7fFXvKt4Beo",
        "outputId": "b10b1c33-8eb6-4c51-803e-7a2642e96e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "\n",
        "    pairs = set(pairs)\n",
        "    return pairs\n",
        "print(get_pairs('Hôm_nay'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('n', 'a'), ('m', '_'), ('ô', 'm'), ('a', 'y'), ('_', 'n'), ('H', 'ô')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xgZ30tg4wMj",
        "outputId": "fef9017a-1d21-4e66-ac86-c96d87cf3596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('bpe.codes', encoding=\"utf-8\") as merges_handle:\n",
        "  merges = merges_handle.read().split(\"\\n\")[:-1]\n",
        "\n",
        "merges = [tuple(merge.split()[:-1]) for merge in merges]\n",
        "bpe_ranks = dict(zip(merges, range(len(merges))))\n",
        "cache = {}\n",
        "\n",
        "def bpe(token):\n",
        "  if token in cache:\n",
        "    return cache[token]\n",
        "  word = tuple(token)\n",
        "  word = tuple(list(word[:-1]) + [word[-1] + \"</w>\"])\n",
        "  pairs = get_pairs(word)\n",
        "\n",
        "  if not pairs:\n",
        "    return token\n",
        "\n",
        "  while True:\n",
        "    bigram = min(pairs, key=lambda pair: bpe_ranks.get(pair, float(\"inf\")))\n",
        "    if bigram not in bpe_ranks:\n",
        "      break\n",
        "    first, second = bigram\n",
        "    new_word = []\n",
        "    i = 0\n",
        "    while i < len(word):\n",
        "      try:\n",
        "        j = word.index(first, i)\n",
        "      except ValueError:\n",
        "        new_word.extend(word[i:])\n",
        "        break\n",
        "      else:\n",
        "        new_word.extend(word[i:j])\n",
        "        i = j\n",
        "\n",
        "      if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
        "        new_word.append(first + second)\n",
        "        i += 2\n",
        "      else:\n",
        "        new_word.append(word[i])\n",
        "        i += 1\n",
        "    new_word = tuple(new_word)\n",
        "    word = new_word\n",
        "    if len(word) == 1:\n",
        "      break\n",
        "    else:\n",
        "      pairs = get_pairs(word)\n",
        "  word = \"@@ \".join(word)\n",
        "  word = word[:-4]\n",
        "  cache[token] = word\n",
        "  return word\n",
        "\n",
        "print(bpe('Viblo'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vi@@ b@@ lo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWel1NUh7bxQ",
        "outputId": "7fd5fdd6-e8c2-4ee6-a7c1-fb7c129c478f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "def _tokenize(text):\n",
        "    \"\"\"Tokenize a string.\"\"\"\n",
        "    split_tokens = []\n",
        "\n",
        "    words = re.findall(r\"\\S+\\n?\", text)\n",
        "\n",
        "    for token in words:\n",
        "        split_tokens.extend([t for t in bpe(token).split(\" \")])\n",
        "    return split_tokens\n",
        "\n",
        "print(_tokenize('Hôm_nay trời nóng quá nên tôi ở nhà viết Viblo!'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hôm_nay', 'trời', 'nóng', 'quá', 'nên', 'tôi', 'ở', 'nhà', 'viết', 'Vi@@', 'blo@@', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6acVhfz9AZrF"
      },
      "source": [
        "encoder = {}\n",
        "bos_token=\"<s>\"\n",
        "eos_token=\"</s>\"\n",
        "sep_token=\"</s>\"\n",
        "cls_token=\"<s>\"\n",
        "unk_token=\"<unk>\"\n",
        "pad_token=\"<pad>\"\n",
        "mask_token=\"<mask>\"\n",
        "\n",
        "\n",
        "encoder[bos_token] = 0\n",
        "encoder[pad_token] = 1\n",
        "encoder[eos_token] = 2\n",
        "encoder[unk_token] = 3\n",
        "\n",
        "def add_from_file(f):\n",
        "  if isinstance(f, str):\n",
        "      try:\n",
        "          with open(f, \"r\", encoding=\"utf-8\") as fd:\n",
        "              add_from_file(fd)\n",
        "      except FileNotFoundError as fnfe:\n",
        "          raise fnfe\n",
        "      except UnicodeError:\n",
        "          raise Exception(\"Incorrect encoding detected in {}, please \" \"rebuild the dataset\".format(f))\n",
        "      return\n",
        "\n",
        "  lines = f.readlines()\n",
        "  for lineTmp in lines:\n",
        "      line = lineTmp.strip()\n",
        "      idx = line.rfind(\" \")\n",
        "      if idx == -1:\n",
        "          raise ValueError(\"Incorrect dictionary format, expected '<token> <cnt>'\")\n",
        "      word = line[:idx]\n",
        "      encoder[word] = len(encoder)\n",
        "\n",
        "add_from_file('vocab.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pcz9F29_Sgz",
        "outputId": "01213f3f-7b26-448a-c224-615aa34ab9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def _convert_token_to_id(token):\n",
        "    \"\"\" Converts a token (str) in an id using the vocab. \"\"\"\n",
        "    return encoder.get(token, encoder.get(unk_token))\n",
        "print(_convert_token_to_id('Hôm_nay'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v59YJ4MJF3xu",
        "outputId": "cc5b51c1-a994-4691-8924-4bbd31f36368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = {v: k for k, v in encoder.items()}\n",
        "def _convert_id_to_token(index):\n",
        "    return decoder.get(index, unk_token)\n",
        "\n",
        "print(_convert_id_to_token(7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "của\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iSccuIU7rn3",
        "outputId": "c47204ad-4001-4c85-9cfc-4a07bb27f884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def convert_tokens_to_string(tokens):\n",
        "    out_string = \" \".join(tokens)\n",
        "    out_string = out_string.replace(\"@@ \", \"\").strip()\n",
        "    out_string = out_string.replace('@@','').strip()\n",
        "    return out_string\n",
        "  \n",
        "print(convert_tokens_to_string(['Hôm_nay', 'trời', 'nóng', 'quá' ,'nên', 'tôi', 'ở', 'nhà', 'viết', 'Vi@@', 'blo@@']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hôm_nay trời nóng quá nên tôi ở nhà viết Viblo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGKL3T4d0l8J"
      },
      "source": [
        "# Requirement\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZTb_7oezVdQ",
        "outputId": "13ad52ec-15bb-4e01-8674-b8da9e6943c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install pandas\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLNQV9Y9Wf1l",
        "outputId": "91ed51f5-4908-4be4-d0f4-4bfaf98c421b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=8861c4aa4eae69235b0aa588ae471189df60e1aa8f8fc9faa65afae74903dd71\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0uUbDt0tmE",
        "outputId": "b8520941-4e04-4e09-d8b4-1c532a30b3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! pip install torch torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52mxnz7V4nMG",
        "outputId": "a6603ae9-17e2-49f1-b0da-126c13c74cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! pip3 install vncorenlp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=9b24db0ced03fd5cf4bec6e3e73b9bd789e2267e84d7e4a2b0e8ac57aafd1550\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niPCrVSQ4xWY"
      },
      "source": [
        "# ! rm -rf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhN1qnIx08Og",
        "outputId": "e3bd57bb-d8b5-4e0f-c442-91ecd942a90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "! mkdir -p vncorenlp/models/wordsegmenter\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "! wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "! mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "! mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "! mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-26 10:14:53--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27412575 (26M) [application/octet-stream]\n",
            "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
            "\n",
            "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  44.7MB/s    in 0.6s    \n",
            "\n",
            "2020-10-26 10:14:54 (44.7 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
            "\n",
            "--2020-10-26 10:14:55--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 526544 (514K) [application/octet-stream]\n",
            "Saving to: ‘vi-vocab’\n",
            "\n",
            "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-10-26 10:14:55 (7.59 MB/s) - ‘vi-vocab’ saved [526544/526544]\n",
            "\n",
            "--2020-10-26 10:14:55--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128508 (125K) [text/plain]\n",
            "Saving to: ‘wordsegmenter.rdr’\n",
            "\n",
            "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-10-26 10:14:55 (3.16 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjjCGJ5I1Y41"
      },
      "source": [
        "from vncorenlp import VnCoreNLP\n",
        "import re\n",
        "\n",
        "rdrsegmenter = VnCoreNLP(\"/content/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n",
        "def document_2_list_token(documents):\n",
        "  vocab = {}\n",
        "  for document in documents:\n",
        "    tokenizer = rdrsegmenter.tokenize(document)\n",
        "    for sentence in tokenizer:\n",
        "      for token in sentence:\n",
        "        token = token.lower()\n",
        "        if not re.search('[a-zA-Z]',token):\n",
        "          continue\n",
        "        if token != '':\n",
        "          if token not in vocab:\n",
        "            vocab[token] = 1\n",
        "          else:\n",
        "            vocab[token] += 1\n",
        "  return vocab\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrl9awb1Sz6W"
      },
      "source": [
        "# Entity Feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EurK-p8WP8t",
        "outputId": "40a865c1-28b3-4ac5-dfd7-c6188d81b64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "908c6fef715d40ee8d7bb78f82613c32",
            "c681a216eca548d99660e238f2effa58",
            "12912f6b19554f429285560be96cf976",
            "cb10a740e8cc4d3a98dcd9bb7f43ec21",
            "329bfa4898704015a63cf8180f208ca0",
            "1409e61867954f6b9731212bcf97329c",
            "044b1f28fef5439c9488cb805d3f6758",
            "5da01728072a4208bff5f674d5de5064",
            "73db3e25f26449119cadc9b2eb08c09b",
            "a8ee4701403c4933b345663ece140915",
            "0182f666d78a4f7d812b1a0fa6eb91ab",
            "07b8dd95bdd84d5890c6a1278866be90",
            "d4ea66dbc5574a708d9957267fe82f20",
            "c7093c5ab0ba45e7805030e9ba3b04f6",
            "63639ed1f1ee42d6a654e5493f67848b",
            "16734bba3c1944aabab30d5a7f09aa4d",
            "2955c6100dda41beae27ab084139e1a5",
            "0c693fd22dbd4cdf8e57b055a91382de",
            "fc4c490f48c94585be0d33a473de5822",
            "d8cdc6e2b8fc4c819a1eb475c15abc2a",
            "ed7284585c194b61b36854ddefe47ad1",
            "6115a0dd1f264ea0895ea4b8ce9ade2b",
            "f695b875b66e42e2816111c6e393117e",
            "166aa820d59e41ff8f2c8d4303813f52",
            "885e2fdc88e54406afe3c2a241899614",
            "b53d5cd5b25c46fe8fe3313aab47f15a",
            "634615d0abeb4d899f0f3d9af72f66dc",
            "9bf585ad7993415c9fad9ab306fae675",
            "33aa7e0f54914a59874623eb3b591b49",
            "771fb73a47394b7da42398d85d2c93cc",
            "e78112261cd347ed9794111d4a331ebb",
            "99d26586f8a84e5fbc8c5f4104395c47"
          ]
        }
      },
      "source": [
        "import  torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from vncorenlp import VnCoreNLP\n",
        "import numpy as np\n",
        "\n",
        "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "908c6fef715d40ee8d7bb78f82613c32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73db3e25f26449119cadc9b2eb08c09b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=542923308.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2955c6100dda41beae27ab084139e1a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "885e2fdc88e54406afe3c2a241899614",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2bx-TMmX3qf"
      },
      "source": [
        "def get_token_line(text):\n",
        "  tokens_line = rdrsegmenter.tokenize(text)\n",
        "  line = \" \"\n",
        "  sentence = ''\n",
        "  for line in tokens_line:\n",
        "    line = ' '.join(token for token in tokens_line[0])\n",
        "    sentence += line + ' '\n",
        "    line = ' '\n",
        "  return sentence\n",
        "\n",
        "def get_token_list(text):\n",
        "  tokens_line = rdrsegmenter.tokenize(text)\n",
        "  sentence = []\n",
        "  for line in tokens_line:\n",
        "   sentence.extend(line)\n",
        "  return sentence\n",
        "\n",
        "def get_input_ids(text):\n",
        "  sentence = get_token_line(text)\n",
        "  input_id = torch.tensor([tokenizer.encode(sentence)])\n",
        "  return input_id\n",
        "\n",
        "def get_features_senten(text):\n",
        "  input_id = get_input_ids(text)\n",
        "  with torch.no_grad():\n",
        "      features = phobert(input_id)  \n",
        "  cls_token = features[0][0][0]\n",
        "  pooling = np.zeros(768)\n",
        "  for token in features[0][0]:\n",
        "    pooling = np.add(pooling,token)\n",
        "  return cls_token,pooling/(len(input_id))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASum3X3YX8vI"
      },
      "source": [
        "from scipy import spatial\n",
        "def similar_2_sen(text1 , text2, is_pooling = True):\n",
        "  text1 = text1.lower()\n",
        "  text2 = text2.lower()\n",
        "  cls_token1, pooling1 = get_features_senten(text1)\n",
        "  cls_token2, pooling2 = get_features_senten(text2)\n",
        "  if is_pooling:\n",
        "    vec1 = pooling1\n",
        "    vec2 = pooling2\n",
        "  else:\n",
        "    vec1 = cls_token1\n",
        "    vec2 = cls_token2\n",
        "  dataSetI = vec1.tolist()\n",
        "  dataSetII = vec2.tolist()\n",
        "  result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
        "  return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo2Kudn9YG7e"
      },
      "source": [
        "class_construction_land = ['là đất thổ cư','đất ở','trong đó thổ cư','đất ở lâu dài','thổ cư','diện tích xây dựng','diện tích sử dụng','nhà rộng','nhà xây','ont','diện tích đất ở','dt đất ở','dt sử dụng','dt nhà','diện tích nhà']\n",
        "other_type_land = ['diện tích vườn','diện tích ao','diện tích nông nghiệp','diện tích mái','diện tích sản xuất','đất trồng cây lâu năm']\n",
        "# other_type_land = []\n",
        "total_land = ['lô đất','tổng dt','tổng diện tích']\n",
        "# total_land =[]\n",
        "\n",
        "def computing_max_ability(text,class_area):\n",
        "  text = text.lower()\n",
        "  max = 0\n",
        "  context_ability = ''\n",
        "  class_patent = []\n",
        "  if class_area == 1:\n",
        "    class_patent = class_construction_land\n",
        "  if class_area == 2:\n",
        "    class_patent = other_type_land\n",
        "  if class_area == 3:\n",
        "    class_patent = total_land\n",
        "  for item in class_patent:\n",
        "    item = get_token_list(item)\n",
        "    item = ' '.join(x for x in item)\n",
        "    similar = similar_2_sen(text,item)\n",
        "    # print(text ,'------', item,'-----',similar)\n",
        "    if similar > max :\n",
        "      max = similar\n",
        "      context_ability = item\n",
        "  # print(context_ability)\n",
        "  return max "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G0F5zmaYMdb"
      },
      "source": [
        "import re\n",
        "def  clean_text(text):\n",
        "  text = re.sub('[:\\'\"|`~]','',text)\n",
        "  return text\n",
        "\n",
        "\n",
        "# print(clean_text('diện tích :'))\n",
        "class classifier_area:\n",
        "  def __init__(self, ner_result):\n",
        "    self.input = ner_result\n",
        "  \n",
        "  def get_position_of_area(self):\n",
        "    result = []\n",
        "    for item in self.input['labels']:\n",
        "      if item[2] == 'size':\n",
        "        result.append(item)  \n",
        "    return result\n",
        "      \n",
        "  def get_context_of_entity(self):\n",
        "    context_menu = []\n",
        "    position_area_entity = self.get_position_of_area()\n",
        "    for item in position_area_entity:\n",
        "      context_before = []\n",
        "      context_menu.append([item[0] , item[1]])\n",
        "#----------------------------------------------------------------      \n",
        "      if position_area_entity.index(item) > 0:\n",
        "        index_before = position_area_entity.index(item)\n",
        "        text_before = self.input['text'][position_area_entity[index_before - 1][1]:item[0]]\n",
        "        text_before = clean_text(text_before)\n",
        "      else:\n",
        "        text_before =  self.input['text'][:item[0]]\n",
        "      text_before = get_token_list(text_before)\n",
        "      text_before = list(text_before)\n",
        "      text_before.reverse()\n",
        "      # print((text_before))\n",
        "      end_senten_pattent = ['.',',','?','!','-','+',')','(','...']\n",
        "      if len(text_before) > 0:\n",
        "        if text_before[0] not in end_senten_pattent:\n",
        "          for token in text_before:\n",
        "            if token not in end_senten_pattent and len(context_before) < 3:\n",
        "              context_before.append(token)\n",
        "            else:\n",
        "              break\n",
        "      context_before.reverse()\n",
        "      if len(context_before) > 0:\n",
        "        context_menu[-1].append(' '.join(x for x in context_before))\n",
        "# -----------------------------------------------------------------------\n",
        "      context_after = []\n",
        "      if position_area_entity.index(item) < len(position_area_entity)-1:\n",
        "        index_after = position_area_entity.index(item)\n",
        "        text_after = self.input['text'][item[1]:position_area_entity[index_after+1][0]]\n",
        "        text_after = clean_text(text_after)\n",
        "      else:\n",
        "        text_after = self.input['text'][item[1]:]\n",
        "      text_after = list(get_token_list(text_after))\n",
        "      # print(text_after)\n",
        "      if len(text_after) > 0:\n",
        "        if text_after[0] not in end_senten_pattent:\n",
        "          for token in text_after:\n",
        "            if token not in end_senten_pattent and len(context_after) < 3:\n",
        "              context_after.append(token)\n",
        "            else:\n",
        "              break\n",
        "      if len(context_after) > 0:\n",
        "        context_menu[-1].append(' '.join(x for x in context_after))\n",
        "    return context_menu \n",
        "\n",
        "  def computing_similar(self):\n",
        "    labels = []\n",
        "    contexts = self.get_context_of_entity()\n",
        "    for context in contexts:\n",
        "      max = 0\n",
        "      classs = 0\n",
        "      context_text = context[2:]\n",
        "      # print(context_text)\n",
        "      for text in context_text:\n",
        "        for i in range(1,4):\n",
        "          computed = computing_max_ability(text,i)\n",
        "          # print(computed)\n",
        "          if max < computed:\n",
        "            max = computed\n",
        "            classs = i\n",
        "\n",
        "      labels.append(list([classs,max]))\n",
        "    return labels  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybNsOvcdYSD4"
      },
      "source": [
        "import re\n",
        "\n",
        "def get_number_floor(data):\n",
        "  map = {'một':'1', 'hai':'2', 'ba':'3', 'bốn':'4', 'năm':'5', 'sáu':'6', 'bảy':'7', 'tám':'8', 'chín':'9', 'không':'0'}\n",
        "  max_floor = 0 \n",
        "  text = ''\n",
        "  for item in data['labels']:\n",
        "    if 'floor' in item[2].split('_') :\n",
        "      # print(data['text'][item[0]:item[1]])\n",
        "      text = data['text'][item[0]:item[1]]\n",
        "      transform = ''\n",
        "      for item in text.split(' '):\n",
        "        if item in map : \n",
        "          transform += ' ' + map[item]\n",
        "        else:\n",
        "          transform +=' ' + item\n",
        "      text = transform\n",
        "      if re.search('(\\d+\\D\\d+)',text):\n",
        "        floor_patent = re.search('(\\d+\\D\\d+)',text).group()\n",
        "        if re.search('\\.|,',floor_patent):\n",
        "          floor = float(re.sub('\\D','.',floor_patent))\n",
        "        else:\n",
        "          floor = [float(x) for x in re.split('\\D+',floor_patent)]\n",
        "        # floor = [int(x) for x in floor]\n",
        "          floor =  max(floor)\n",
        "        if max_floor < floor:\n",
        "          max_floor = floor\n",
        "      else:\n",
        "        floor = text.split(' ')\n",
        "        for token in floor:\n",
        "          token = re.sub('\\D','',token)\n",
        "          if token.isdigit():\n",
        "            if float(token) > max_floor:\n",
        "              max_floor = float(token)\n",
        "        # print('floor',max_floor)\n",
        "        # if max_floor < floor:\n",
        "        #   max_floor = floor\n",
        "\n",
        "  if text == '':\n",
        "    return 1\n",
        "  return float(max_floor)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfD0tgNoYXbC"
      },
      "source": [
        "import re\n",
        "def area_process(input):\n",
        "  classifier = classifier_area(input)\n",
        "  ability = classifier.computing_similar()\n",
        "  position = classifier.get_position_of_area()\n",
        "  # print(ability)\n",
        "  # print(position)\n",
        "  # 1/0\n",
        "  number_floor = get_number_floor(input)\n",
        "  area = {'use_area':0,'total_land_area':0,'contruction_area':0}\n",
        "  area_content =  []\n",
        "  for item in position:\n",
        "    area_content.append(input['text'][item[0]:item[1]])\n",
        "  # print(area_content)\n",
        "\n",
        "  numberic_value =[]\n",
        "  for item in area_content:\n",
        "    item = item.lower()\n",
        "    if re.search('\\d*[\\.*,*]*\\d+\\s*(m|ha)',item):\n",
        "      value = re.search('\\d*[\\.*,*]*\\d+\\s*(m|ha)',item).group()\n",
        "      value = re.sub('m2','',value)\n",
        "      value = re.sub('ha','',value)\n",
        "      value = re.sub('m','',value)\n",
        "      value = re.sub(',','.',value)\n",
        "      # print(value)\n",
        "      # 1/0\n",
        "      try:\n",
        "        value = float(value)\n",
        "      except:\n",
        "        value = re.sub('\\D','',value)\n",
        "      numberic_value.append(float(value))\n",
        "\n",
        "  max_consistent_construction = 0\n",
        "  construction_value = 0\n",
        "  # print((numberic_value))\n",
        "  for index in range(len(numberic_value)):\n",
        "    # print(index)\n",
        "    classified = list(ability[index])\n",
        "    # print(classified)\n",
        "    # 1/0\n",
        "    if classified[0] ==  1:\n",
        "      if max_consistent_construction < classified[1] or (max_consistent_construction == classified[1] and numberic_value[index] < construction_value):\n",
        "        max_consistent_construction = classified[1]\n",
        "        construction_value = numberic_value[index]\n",
        "  # print(max_consistent_construction,construction_value)\n",
        "  max_total_area = 0\n",
        "  for index in range(len(numberic_value)):\n",
        "    classified = list(ability[index])\n",
        "    if numberic_value[index] > construction_value:\n",
        "    # if classified[1] < 0.53:\n",
        "      if max_total_area < numberic_value[index] and numberic_value[index] != number_floor*construction_value:\n",
        "        max_total_area = numberic_value[index]\n",
        "    # if classified[0] == 1 and max_total_area < numberic_value[index] and numberic_value[index] != number_floor*construction_value:\n",
        "      # max_total_area = numberic_value[index]\n",
        "  # print(max_total_area)\n",
        "  if max_total_area == 0:\n",
        "    max_total_area = construction_value\n",
        "  if construction_value == 0:\n",
        "    construction_value = max_total_area\n",
        "  # print('num floor:' , number_floor)\n",
        "  area['use_area'] = construction_value*number_floor\n",
        "  area['total_land_area'] = max_total_area\n",
        "  area['contruction_area'] = construction_value\n",
        "  return area"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPrxQSFkYcCk"
      },
      "source": [
        "def combine_house_entity(input):\n",
        "  area = area_process(input)\n",
        "  number_floor = get_number_floor(input)\n",
        "  slot = {'house_sizes':area,'house_description':{'floor':0,'mat_tien':'','size_mat_ngo':'','number_livingroom':'','number_kitchen':'','number_dressroom':'','number_bedroom':''},\n",
        "          'land_description':{},'price':0,'house_locate':{'near_places':'','location':''},'contact':{'contact_mobile':'','email':''}}\n",
        "  for item in input['labels']:\n",
        "    # print(item[2])\n",
        "    if item[2] in slot['house_description']:\n",
        "      if  slot['house_description'][item[2]] == '' or slot['house_description'][item[2]] == 0:\n",
        "        slot['house_description'][item[2]] = input['text'][item[0]:item[1]]\n",
        "      # print(slot['house_description'][item[2]])\n",
        "      # 1/0\n",
        "  \n",
        "    if item[2] in slot['house_locate']:\n",
        "      slot['house_locate'][item[2]] += input['text'][item[0]:item[1]] + ' '\n",
        "  \n",
        "    if item[2] in slot['contact']:\n",
        "      slot['contact'][item[2]] = input['text'][item[0]:item[1]]\n",
        "\n",
        "    if item[2] in slot:\n",
        "      slot[item[2]] = input['text'][item[0]:item[1]]\n",
        "  \n",
        "  slot['house_description']['floor'] = number_floor\n",
        "  # print(slot)\n",
        "  return slot"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N90u2XHDYdg8"
      },
      "source": [
        "print(combine_house_entity(data[1000]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iy2De0536h3"
      },
      "source": [
        "# Content Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0RHqTbet4S6",
        "outputId": "e430f2e5-6ce0-4c53-da51-a78dd960d494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open('a.json','r',encoding='utf-8') as file:\n",
        "  data = json.load(file)\n",
        "print(len(data))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cbSUDkxzZdM",
        "outputId": "44a6409f-22f6-4405-9e87-abd8b9a91afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from itertools import islice\n",
        "\n",
        "dfs = pd.read_excel('data_classifier.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "check_nan_land = dfs['land'].isnull()\n",
        "colum_land = list(dfs['land'])\n",
        "check_nan_house = dfs['house'].isnull()\n",
        "colum_house = list(dfs['house'])\n",
        "\n",
        "index_land = []\n",
        "index_house = []\n",
        "\n",
        "for index1 in range(len(colum_land)):\n",
        "  if not check_nan_land[index1]:\n",
        "    index_land.append(int(colum_land[index1]))\n",
        "\n",
        "for index1 in range(len(colum_house)):\n",
        "  if not check_nan_house[index1]:\n",
        "    index_house.append(int(colum_house[index1]))\n",
        "\n",
        "data_land = [data[index]['text'] for index in index_land]\n",
        "data_house = [data[index]['text'] for index in index_house]\n",
        "\n",
        "\n",
        "count_feature_land = document_2_list_token(data_land)\n",
        "count_feature_land = {k: v for k, v in sorted(count_feature_land.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# data_house = data_house[:index2]\n",
        "count_feature_house = document_2_list_token(data_house)\n",
        "count_feature_house = {k: v for k, v in sorted(count_feature_house.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"Return first n items of the iterable as a list\"\n",
        "    return list(islice(iterable, n))\n",
        "print(take(50,count_feature_land.items()))\n",
        "print(take(50,count_feature_house.items()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('có', 200), ('đất', 190), ('nhà', 139), ('bán', 109), ('cách', 82), ('đường', 81), ('giá', 74), ('chính', 67), ('chủ', 66), ('sổ_đỏ', 58), ('cấp', 57), ('khu', 57), ('gần', 55), ('và', 54), ('rất', 53), ('liên_hệ', 52), ('diện_tích', 51), ('cần', 47), ('lô', 42), ('hà_nội', 41), ('cho', 40), ('tỷ', 39), ('ô_tô', 38), ('đẹp', 38), ('trong', 36), ('chỉ', 36), ('nhà_đất', 35), ('nhu_cầu', 35), ('lại', 35), ('là', 33), ('vị_trí', 32), ('vuông_vắn', 32), ('được', 32), ('pháp_lý', 30), ('lh', 30), ('đầy_đủ', 27), ('rộng', 27), ('thuận_tiện', 27), ('m', 26), ('không', 26), ('làm', 26), ('tầng', 26), ('mảnh', 25), ('chợ', 25), ('thông_tin', 25), ('tại', 25), ('mặt_tiền', 24), ('vào', 24), ('an_ninh', 24), ('m2', 24)]\n",
            "[('nhà', 363), ('tầng', 299), ('phòng', 284), ('có', 143), ('cách', 136), ('chính', 122), ('gần', 119), ('giá', 112), ('ngủ', 112), ('tỷ', 110), ('sổ_đỏ', 108), ('bán', 106), ('chủ', 105), ('và', 104), ('đường', 99), ('bếp', 95), ('sân', 90), ('khu', 87), ('khách', 85), ('cửa', 76), ('rộng', 68), ('diện_tích', 68), ('pháp_lý', 68), ('vị_trí', 67), ('xây', 66), ('phơi', 63), ('chỉ', 63), ('thiết_kế', 62), ('gỗ', 62), ('ô_tô', 59), ('nội_thất', 59), ('các', 58), ('wc', 57), ('mới', 56), ('thờ', 55), ('đầy_đủ', 52), ('liên_hệ', 52), ('thoáng', 51), ('chợ', 51), ('rất', 50), ('m', 47), ('ngõ', 44), ('hỗ_trợ', 43), ('đẹp', 43), ('trường', 43), ('thương_lượng', 42), ('thanh_hà', 42), ('lh', 41), ('hướng', 40), ('trước', 40)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFERuDc77qfk"
      },
      "source": [
        "vocabulary_land = ['đất','nhà','lô','nhà_đất','vuông_vắn','vườn','mảnh','xưởng','kho']\n",
        "vocabulary_house = ['tầng','phòng','ngủ','bếp','khách','sân','thiết_kế','phơi','thờ','nội_thất','wc','hướng',',mặt_tiền','vệ_sinh','cửa','ban_công','tiện_nghi']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBRMeH-9GJK3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = []\n",
        "  document = rdrsegmenter.tokenize(text)\n",
        "  for senten in document:\n",
        "    for token in senten:\n",
        "      tokens.append(token.lower())\n",
        "  return tokens\n",
        "\n",
        "def transform_document_to_vec(input):\n",
        "  text = input['text']\n",
        "  vocab = vocabulary_land\n",
        "  for item in vocabulary_house:\n",
        "    if item not in vocab:\n",
        "      vocab.append(item)\n",
        "  \n",
        "  text = text.lower()\n",
        "  vectorizer = CountVectorizer(tokenizer=tokenize,vocabulary=vocab,binary=True)\n",
        "  # print(vectorizer.build_tokenizer())\n",
        "  # 1/0\n",
        "  X = vectorizer.fit_transform([text]).toarray()\n",
        "  return X\n",
        "\n",
        "def transform_entity_to_vec(input):\n",
        "  slot = combine_house_entity(input)\n",
        "  vec = np.zeros(7)\n",
        "  for item in slot['house_description']:\n",
        "    if slot['house_description'][item] not in ['',0]:\n",
        "      vec[list(slot['house_description'].keys()).index(item)] = 1\n",
        "  return vec , slot\n",
        "\n",
        "# print(transform_entity_to_vec(data[1001]))\n",
        "# 1/0\n",
        "def convert_labels(y, C = 2):\n",
        "    Y = sparse.coo_matrix((np.ones_like(y),\n",
        "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
        "    return Y.T\n",
        "\n",
        "# a = transform_document_to_vec('Bán nhà 40m2x 3 tầng mới đường oto đỗ cửa giá 1.38 tỷ có TL ... Hướng : Đông Nam ... Diện tích : 40m2 nở hậu ... Vị trí : Nhà có vị trí cực thuận tiện gần trường học các cấp , công an phường , quân đội , nhà văn hóa . Nhà gần bãi gửi xe ngày đêm , đường trước nhà rộng 3 cực thoáng trong dãy phân lô cao tầng ... + Nhà gần trục đường 6 tuyến đi Hà Đông , Ngã Tư Sở , Mỹ Đình hay tuyến Chương Mỹ , Hòa Bình ... + Nhà gần nhiều dự án trọng đểm của quận Hà Đông là khu đang phát triển rất mạnh .. ... + Khu dân cư đông , an ninh tốt , hàng xóm thân thiện .. ... + Nhà gần điểm xe bus cách đường quốc lộ 6 chỉ 500m ... + Với tài chính vừa phải bạn sở hữu căn nhà lý tưởng ... Thiết kế : Theo kiến trúc tân cổ điển , rộng , thoáng , tầng 2 phòng ngủ ... + Tâng 1 : Phòng khách , để xe , bếp ăn riêng , có sân sau ... + Tầng 2 : 2 phòng ngủ rộng , 1 wc ... + Tầng 3 : 1 phòng ngủ , 1 phòng thờ , sân phơi rộng ... + Nhà có sân trước 3m , sân sau 1,5m các phòng đều có cửa sổ rộng , không khí lưu thông ... Nội thất : Hoàn thiện đầy đủ nội thất cơ bản , nhận nhà ngay ... Pháp lý : Giấy phép xây dựng riêng ... Sổ đỏ chính chủ ... Giá : 1.38 tỷ làm việc trực tiếp , bao sang tên ... Liên hệ : Tuấn Anh 0974322298 đi xem miễn phí ... Hỗ trợ thủ tục vay vốn ngân hàng 70% giá trị với lãi xuất thấp , thủ tục nhanh ... Thông tin pháp lý : Sổ đỏ chính chủ.')\n",
        "# print(a.shape)\n",
        "# Feature_1 = []\n",
        "# Feature_2 = []\n",
        "# label = []\n",
        "# for index in index_house:\n",
        "#   print(index)\n",
        "#   Feature_1.extend(transform_document_to_vec(data[index]))\n",
        "#   Feature_2.append(transform_entity_to_vec(data[index]))\n",
        "#   label.append(0)\n",
        "# for index in index_land:\n",
        "#   print(index)\n",
        "#   Feature_1.extend(transform_document_to_vec(data[index]))\n",
        "#   Feature_2.append(transform_entity_to_vec(data[index]))\n",
        "#   label.append(1)\n",
        "# Feature_1 = np.asarray(Feature_1)\n",
        "# Feature_2 = np.asarray(Feature_2)\n",
        "# Label     = np.asarray(label)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3aIx8Dv1Rbp",
        "outputId": "9689a0f4-268f-4484-e14c-2f4101214117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with open('Feature.npy', 'rb') as f:\n",
        "    a = np.load(f)\n",
        "    b = np.load(f)\n",
        "    c = np.load(f)\n",
        "\n",
        "index_array = range(a.shape[0])\n",
        "\n",
        "index_train, index_test = train_test_split(\n",
        "     index_array, test_size=0.33, random_state=42)\n",
        "# print(a[[1,2,3,4]])\n",
        "# print(index_train)\n",
        "# 1/0\n",
        "Feature1_train = a[index_train]\n",
        "Feature1_test = a[index_test]\n",
        "\n",
        "Feature2_train = b[index_train]\n",
        "Feature2_test = b[index_test]\n",
        "y_train = c[index_train]\n",
        "y_test = c[index_test]\n",
        "\n",
        "y_train =  convert_labels(y_train)\n",
        "y_test  =  convert_labels(y_test)\n",
        "print(Feature2_train.shape)\n",
        "print(Feature1_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123, 7)\n",
            "(123, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5sUkwYqEHm0",
        "outputId": "c5908bac-0d4c-4e71-e27c-8e2d637c2fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y_train),len(y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiGxmYPvHQee",
        "outputId": "c83d5f03-287d-4039-96ba-b290eb660c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Feature1_train.shape , Feature2_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(123, 26) (61, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLkYUPkE7rGm",
        "outputId": "a576f830-e0e1-411c-95db-eac57d37aa4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "! git clone https://github.com/thanhlong1997/bert_quora"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_quora'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 630 (delta 21), reused 27 (delta 10), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (630/630), 219.91 KiB | 7.33 MiB/s, done.\n",
            "Resolving deltas: 100% (399/399), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktjm5dwVTF7r"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Parameter\n",
        "learning_rate = 0.001\n",
        "epoch = 150\n",
        "batch_size = 128\n",
        "display_step =5\n",
        "\n",
        "#Network Parameters\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2 = 64\n",
        "dimention_1 = 26 # dimention of vocabulary\n",
        "dimention_2 = 7 # dimention of entities\n",
        "connect_dimention = 16 # dimention connect\n",
        "num_class = 2\n",
        "keep_prob = 0.7\n",
        "batch_size = 32\n",
        "\n",
        "# tf Graph input\n",
        "X_1 = tf.placeholder('float',[None,dimention_1],name='X_1')\n",
        "X_2 = tf.placeholder('float',[None,dimention_2],name='X_2')\n",
        "Y   = tf.placeholder('int64',[None,num_class],name='Y')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKMVXxVW5H1K"
      },
      "source": [
        "! tf_upgrade_v2 \\\n",
        "  --infile bert_quora/modeling.py \\\n",
        "  --outfile modeling_v2.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vzDYHFE4HON"
      },
      "source": [
        "# Store layers weight and bias\n",
        "\n",
        "weights = {\n",
        "    'concat_1': tf.Variable(tf.random_normal([dimention_1,connect_dimention]),name='concat_1'),\n",
        "    'concat_2': tf.Variable(tf.random_normal([dimention_2,connect_dimention]),name='concat_2'),\n",
        "    'h_1'     : tf.Variable(tf.random_normal([connect_dimention,n_hidden_1]),name='h_1'),\n",
        "    'h_2'     : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2]),name='h_2'),\n",
        "    'out'     : tf.Variable(tf.random_normal([n_hidden_2,num_class]),name='out')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b_1' : tf.Variable(tf.random_normal([n_hidden_1]),name='b_1'),\n",
        "    'b_2' : tf.Variable(tf.random_normal([n_hidden_2]),name='b_2'),\n",
        "    'out' : tf.Variable(tf.random_normal([num_class]),name='out')\n",
        "}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okTxSF0s-JRE"
      },
      "source": [
        "# Create model\n",
        "def neural_net(x1,x2):\n",
        "  # Concat Feature\n",
        "  concat  = tf.add(tf.matmul(x1,weights['concat_1']),tf.matmul(x2,weights['concat_2']))\n",
        "  # hidden layer 1\n",
        "  layer_1 = tf.add(tf.matmul(concat,weights['h_1']),biases['b_1'])\n",
        "  layer_norm1 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_1 = layer_norm1(layer_1)\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  # hidden layer 2\n",
        "  layer_2 = tf.add(tf.matmul(layer_1,weights['h_2']),biases['b_2'])\n",
        "  layer_norm2 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_2 = layer_norm2(layer_2)\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  # drop_out\n",
        "  drop_out = tf.nn.dropout(layer_2, keep_prob)\n",
        "  # out layer\n",
        "  out_layer = tf.add(tf.matmul(drop_out,weights['out']),biases['out'])\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  layer_norma = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  out_layer = layer_norma(out_layer)\n",
        "  return out_layer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TSyMOgp_v-i"
      },
      "source": [
        "logit = neural_net(X_1, X_2)\n",
        "\n",
        "# predict = tf.argmax(logit, axis=-1, output_type=tf.int32)\n",
        "# log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "# one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "# per_example_loss = -tf.reduce_sum(Y * log_probs, axis=-1)\n",
        "# loss_op = tf.reduce_mean(per_example_loss)\n",
        "# with tf.variable_scope(\"loss\"):\n",
        "    # I.e., 0.1 dropout\n",
        "    # output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    # logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    # logits = tf.nn.bias_add(logits, output_bias)\n",
        "# probabilities = tf.nn.softmax(logit, axis=-1)\n",
        "# log_probs = tf.nn.log_softmax(logit, axis=-1)\n",
        "\n",
        "    # one_hot_labels = tf.one_hot(Y, depth=num_class, dtype=tf.float32)\n",
        "\n",
        "# per_example_loss = -tf.reduce_sum(Y * log_probs, axis=-1)\n",
        "# loss_op = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "\n",
        "# total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
        "# loss \n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits = logit, labels = Y))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9qDsefjAuLC",
        "outputId": "0e89c0ec-96cc-48f7-fe2c-0beca9a718cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "def training(op):\n",
        "  if op == 'Adam':\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "  elif op == 'RMSprop':\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "  elif op == 'Momentum':\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate)\n",
        "  train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "  predict = tf.argmax(logit, 1)\n",
        "  correct_pred = tf.equal(tf.argmax(logit, 1),tf.argmax(Y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred , tf.float32))\n",
        "  # TP = tf.count_nonzero(tf.matmul(predict , Y))\n",
        "  # TN = tf.count_nonzero((predict - 1) * (Y - 1))\n",
        "  # FP = tf.count_nonzero(predict * (Y - 1))\n",
        "  # FN = tf.count_nonzero((predict - 1) * Y)\n",
        "  # precision = TP / (TP + FP)\n",
        "  # recall = TP / (TP + FN)\n",
        "  # f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "  loss_list = np.zeros(epoch)\n",
        "  init = tf.global_variables_initializer()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(epoch):\n",
        "      batch_feature1,batch_feature2, batch_y = Feature1_train ,Feature2_train, y_train\n",
        "      for i in range(0, (Feature1_train.shape[0] // batch_size) * batch_size, batch_size):\n",
        "        batch_feature2 = Feature2_train[i:i+batch_size]\n",
        "        batch_label = y_train[i:i+batch_size]\n",
        "        loss, _ = sess.run([loss_op, train_op], \n",
        "                           feed_dict = {X_1: np.zeros([batch_size,dimention_1]),\n",
        "                                        X_2 : batch_feature2, Y : batch_label})\n",
        "        # train_loss += loss\n",
        "\n",
        "      # sess.run(train_op, feed_dict={X_1: batch_feature1,\n",
        "                                    # X_2:batch_feature2,\n",
        "                                    # Y :batch_y})\n",
        "      loss , acc , pred,log = sess.run([loss_op, accuracy,predict,logit],feed_dict={X_1: np.zeros([batch_feature1.shape[0],dimention_1]),\n",
        "                                                                                    X_2: Feature2_train,\n",
        "                                                                                    Y : y_train})\n",
        "      # prop = sess.run([probabilities],feed_dict ={X_1: batch_x,\n",
        "                                                  # X_2: np.zeros([batch_x.shape[0],dimention_2])} )\n",
        "      loss_list[step] = loss\n",
        "      if step % display_step == 0 or step == 1:\n",
        "        print('Step '+str(step)+' batch loss = '+ '{:.4f}'.format(loss) + ' trainning acc ='+\n",
        "              '{:.3f}'.format(acc))\n",
        "        save_path = saver.save(sess, \"/content/model/model\" + str(step)+ \".ckpt\")\n",
        "        print(\"Model saved in path: %s\" % save_path)\n",
        "        batch_y_true = np.argmax(y_train, 1)\n",
        "        print(batch_y_true.shape)\n",
        "        print(f1_score(batch_y_true, pred, average='micro'))\n",
        "        print(pred.shape)\n",
        "    print('Testing Acc:',sess.run(accuracy,feed_dict={X_1: np.zeros([Feature1_test.shape[0],dimention_1]),\n",
        "                                                      X_2: Feature2_test,\n",
        "                                                      Y  : y_test}))\n",
        "    test_result = sess.run(predict,feed_dict={X_1: np.zeros([Feature1_test.shape[0],dimention_1]),\n",
        "                                              X_2: Feature2_test,\n",
        "                                              Y  :y_test})\n",
        "    test_true = np.argmax(y_test, 1)\n",
        "    print(f1_score(test_true,test_result, average='micro'))\n",
        "    print(test_result)\n",
        "    print(test_true)\n",
        "  return loss_list\n",
        "\n",
        "adam = training('Adam') "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 batch loss = 1.1720 trainning acc =0.472\n",
            "Model saved in path: /content/model/model0.ckpt\n",
            "(123,)\n",
            "0.4715447154471545\n",
            "(123,)\n",
            "Step 1 batch loss = 0.8234 trainning acc =0.650\n",
            "Model saved in path: /content/model/model1.ckpt\n",
            "(123,)\n",
            "0.6504065040650406\n",
            "(123,)\n",
            "Step 5 batch loss = 1.0088 trainning acc =0.545\n",
            "Model saved in path: /content/model/model5.ckpt\n",
            "(123,)\n",
            "0.5447154471544715\n",
            "(123,)\n",
            "Step 10 batch loss = 0.8873 trainning acc =0.610\n",
            "Model saved in path: /content/model/model10.ckpt\n",
            "(123,)\n",
            "0.6097560975609756\n",
            "(123,)\n",
            "Step 15 batch loss = 0.8100 trainning acc =0.642\n",
            "Model saved in path: /content/model/model15.ckpt\n",
            "(123,)\n",
            "0.6422764227642277\n",
            "(123,)\n",
            "Step 20 batch loss = 0.6981 trainning acc =0.699\n",
            "Model saved in path: /content/model/model20.ckpt\n",
            "(123,)\n",
            "0.6991869918699187\n",
            "(123,)\n",
            "Step 25 batch loss = 0.6144 trainning acc =0.748\n",
            "Model saved in path: /content/model/model25.ckpt\n",
            "(123,)\n",
            "0.7479674796747967\n",
            "(123,)\n",
            "Step 30 batch loss = 0.7933 trainning acc =0.650\n",
            "Model saved in path: /content/model/model30.ckpt\n",
            "(123,)\n",
            "0.6504065040650406\n",
            "(123,)\n",
            "Step 35 batch loss = 0.6985 trainning acc =0.699\n",
            "Model saved in path: /content/model/model35.ckpt\n",
            "(123,)\n",
            "0.6991869918699187\n",
            "(123,)\n",
            "Step 40 batch loss = 0.6204 trainning acc =0.740\n",
            "Model saved in path: /content/model/model40.ckpt\n",
            "(123,)\n",
            "0.7398373983739838\n",
            "(123,)\n",
            "Step 45 batch loss = 0.7251 trainning acc =0.683\n",
            "Model saved in path: /content/model/model45.ckpt\n",
            "(123,)\n",
            "0.6829268292682927\n",
            "(123,)\n",
            "Step 50 batch loss = 0.5744 trainning acc =0.764\n",
            "Model saved in path: /content/model/model50.ckpt\n",
            "(123,)\n",
            "0.7642276422764228\n",
            "(123,)\n",
            "Step 55 batch loss = 0.7238 trainning acc =0.675\n",
            "Model saved in path: /content/model/model55.ckpt\n",
            "(123,)\n",
            "0.6747967479674797\n",
            "(123,)\n",
            "Step 60 batch loss = 0.6778 trainning acc =0.699\n",
            "Model saved in path: /content/model/model60.ckpt\n",
            "(123,)\n",
            "0.6991869918699187\n",
            "(123,)\n",
            "Step 65 batch loss = 0.6235 trainning acc =0.724\n",
            "Model saved in path: /content/model/model65.ckpt\n",
            "(123,)\n",
            "0.7235772357723578\n",
            "(123,)\n",
            "Step 70 batch loss = 0.5642 trainning acc =0.764\n",
            "Model saved in path: /content/model/model70.ckpt\n",
            "(123,)\n",
            "0.7642276422764228\n",
            "(123,)\n",
            "Step 75 batch loss = 0.5845 trainning acc =0.756\n",
            "Model saved in path: /content/model/model75.ckpt\n",
            "(123,)\n",
            "0.7560975609756099\n",
            "(123,)\n",
            "Step 80 batch loss = 0.5424 trainning acc =0.780\n",
            "Model saved in path: /content/model/model80.ckpt\n",
            "(123,)\n",
            "0.7804878048780488\n",
            "(123,)\n",
            "Step 85 batch loss = 0.4726 trainning acc =0.821\n",
            "Model saved in path: /content/model/model85.ckpt\n",
            "(123,)\n",
            "0.8211382113821138\n",
            "(123,)\n",
            "Step 90 batch loss = 0.4449 trainning acc =0.837\n",
            "Model saved in path: /content/model/model90.ckpt\n",
            "(123,)\n",
            "0.8373983739837398\n",
            "(123,)\n",
            "Step 95 batch loss = 0.4149 trainning acc =0.854\n",
            "Model saved in path: /content/model/model95.ckpt\n",
            "(123,)\n",
            "0.8536585365853658\n",
            "(123,)\n",
            "Step 100 batch loss = 0.4037 trainning acc =0.862\n",
            "Model saved in path: /content/model/model100.ckpt\n",
            "(123,)\n",
            "0.861788617886179\n",
            "(123,)\n",
            "Step 105 batch loss = 0.3995 trainning acc =0.862\n",
            "Model saved in path: /content/model/model105.ckpt\n",
            "(123,)\n",
            "0.861788617886179\n",
            "(123,)\n",
            "Step 110 batch loss = 0.4979 trainning acc =0.805\n",
            "Model saved in path: /content/model/model110.ckpt\n",
            "(123,)\n",
            "0.8048780487804877\n",
            "(123,)\n",
            "Step 115 batch loss = 0.4820 trainning acc =0.813\n",
            "Model saved in path: /content/model/model115.ckpt\n",
            "(123,)\n",
            "0.8130081300813008\n",
            "(123,)\n",
            "Step 120 batch loss = 0.4725 trainning acc =0.813\n",
            "Model saved in path: /content/model/model120.ckpt\n",
            "(123,)\n",
            "0.8130081300813008\n",
            "(123,)\n",
            "Step 125 batch loss = 0.4379 trainning acc =0.837\n",
            "Model saved in path: /content/model/model125.ckpt\n",
            "(123,)\n",
            "0.8373983739837398\n",
            "(123,)\n",
            "Step 130 batch loss = 0.4516 trainning acc =0.829\n",
            "Model saved in path: /content/model/model130.ckpt\n",
            "(123,)\n",
            "0.8292682926829268\n",
            "(123,)\n",
            "Step 135 batch loss = 0.4136 trainning acc =0.854\n",
            "Model saved in path: /content/model/model135.ckpt\n",
            "(123,)\n",
            "0.8536585365853658\n",
            "(123,)\n",
            "Step 140 batch loss = 0.3867 trainning acc =0.870\n",
            "Model saved in path: /content/model/model140.ckpt\n",
            "(123,)\n",
            "0.8699186991869918\n",
            "(123,)\n",
            "Step 145 batch loss = 0.4482 trainning acc =0.829\n",
            "Model saved in path: /content/model/model145.ckpt\n",
            "(123,)\n",
            "0.8292682926829268\n",
            "(123,)\n",
            "Testing Acc: 0.8196721\n",
            "0.7868852459016392\n",
            "[1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1]\n",
            "[0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB27K6cz-bIx"
      },
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "tf.reset_default_graph()\n",
        "n_hidden_1 = 256\n",
        "n_hidden_2 = 64\n",
        "dimention_1 = 26 # dimention of vocabulary\n",
        "dimention_2 = 7 # dimention of entities\n",
        "connect_dimention = 16 # dimention connect\n",
        "num_class = 2\n",
        "\n",
        "\n",
        "  # tf Graph input\n",
        "X_11 = tf.placeholder('float',[None,dimention_1],name='X_11')\n",
        "X_21 = tf.placeholder('float',[None,dimention_2],name='X_21')\n",
        "Y1   = tf.placeholder('float',[None,num_class],name='Y1')\n",
        "\n",
        "weights = {\n",
        "    'concat_1': tf.Variable(tf.random_normal([dimention_1,connect_dimention]),name='concat_1'),\n",
        "    'concat_2': tf.Variable(tf.random_normal([dimention_2,connect_dimention]),name='concat_2'),\n",
        "    'h_1'     : tf.Variable(tf.random_normal([connect_dimention,n_hidden_1]),name='h_1'),\n",
        "    'h_2'     : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2]),name='h_2'),\n",
        "    'out'     : tf.Variable(tf.random_normal([n_hidden_2,num_class]),name='out')\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'b_1' : tf.Variable(tf.random_normal([n_hidden_1]),name='b_1'),\n",
        "    'b_2' : tf.Variable(tf.random_normal([n_hidden_2]),name='b_2'),\n",
        "    'out' : tf.Variable(tf.random_normal([num_class]),name='out')\n",
        "}\n",
        "def neural_net(x1,x2):\n",
        "  # Concat Feature\n",
        "  concat  = tf.add(tf.matmul(x1,weights['concat_1']),tf.matmul(x2,weights['concat_2']))\n",
        "  # hidden layer 1\n",
        "  layer_1 = tf.add(tf.matmul(concat,weights['h_1']),biases['b_1'])\n",
        "  layer_norm1 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_1 = layer_norm1(layer_1)\n",
        "  layer_1 = tf.nn.relu(layer_1)\n",
        "  # hidden layer 2\n",
        "  layer_2 = tf.add(tf.matmul(layer_1,weights['h_2']),biases['b_2'])\n",
        "  layer_norm2 = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  layer_2 = layer_norm2(layer_2)\n",
        "  layer_2 = tf.nn.relu(layer_2)\n",
        "  # drop_out\n",
        "  drop_out = tf.nn.dropout(layer_2, keep_prob)\n",
        "  # out layer\n",
        "  out_layer = tf.add(tf.matmul(drop_out,weights['out']),biases['out'])\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  layer_norma = tf.keras.layers.LayerNormalization(axis = -1)\n",
        "  out_layer = layer_norma(out_layer)\n",
        "  # out_layer = tf.keras.layers.LayerNormalization(axis=1)(out_layer)\n",
        "  return out_layer\n",
        "\n",
        "def predict_raw_text(input):\n",
        "  # graph_meta = tf.train.import_meta_graph('/content/model/model95.ckpt.meta')\n",
        "  logits = neural_net(X_11, X_21)\n",
        "  probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "  predict = tf.argmax(logits, 1)\n",
        "  vector1 = transform_document_to_vec(input)\n",
        "  vector2,slot = transform_entity_to_vec(input)\n",
        "  vector2 = vector2.reshape([1,7])\n",
        "  with tf.Session() as sess:\n",
        "    # graph_meta.restore(sess , tf.train.latest_checkpoint('/content/model'))\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, '/content/model/model145.ckpt')\n",
        "    pred , prop ,log = sess.run([predict,probabilities,logits],feed_dict={X_11: vector1,\n",
        "                                       X_21: vector2})\n",
        "  \n",
        "  return pred[0], prop\n",
        "\n",
        "# print(predict_raw_text('Bán gấp nhà Văn Điển 5 tầng ô tô đỗ gần chỉ 2,7 tỷ ... + Nhà mới đẹp Văn Điển ở ngay , ô tô đỗ gần , công năng đầy đủ cho 1 hộ gia đình ở : 1 khách , bếp , 2 ngủ , 3wc , phòng thờ , sân phơi . Có thể lên thêm 2 tầng thoải mái ... + Nhà Văn Điển gần rất nhiều tiện ích : chợ , trung tâm thương mại , bệnh viện , trung tâm thể dục thể thao , huyện ủy thanh trì ... + Khu vực Thanh Trì sắp lên Quận giá trị bất động sản ngày một tang , khách mua năm sbawts tình hình mua đợt này dịch giá có bớt cho ai thiện chí ... + Khu vực Thanh trì lên trung tâm thành phố rất gần chỉ 15 phút , đi các quận rất thuận tiện , về quê qua bến xe nước ngầm chỉ 2 phút ... + Nhà đẹp sổ vuông nở hậu ... + Liên hệ Mrs Thúy : 0965 - 2535 - 83'))\n",
        "# 1/0"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFuJ0JJsTTl",
        "outputId": "65d2b92b-6277-4874-8713-fe56bc0b2854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(predict_raw_text(data[1001]))"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/model/model145.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,256] vs. [2]\n\t [[{{node layer_normalization/mul_2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-334-cc16eb3b9891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_raw_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-333-77eefb64b705>\u001b[0m in \u001b[0;36mpredict_raw_text\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/model/model145.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     pred , prop ,log = sess.run([predict,probabilities,logits],feed_dict={X_11: vector1,\n\u001b[0;32m---> 69\u001b[0;31m                                        X_21: vector2})\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,256] vs. [2]\n\t [[node layer_normalization/mul_2 (defined at <ipython-input-333-77eefb64b705>:36) ]]\n\nOriginal stack trace for 'layer_normalization/mul_2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-334-cc16eb3b9891>\", line 1, in <module>\n    print(predict_raw_text(data[1001]))\n  File \"<ipython-input-333-77eefb64b705>\", line 56, in predict_raw_text\n    logits = neural_net(X_11, X_21)\n  File \"<ipython-input-333-77eefb64b705>\", line 36, in neural_net\n    layer_1 = layer_norm1(layer_1)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 776, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\", line 1258, in call\n    outputs = outputs * math_ops.cast(scale, outputs.dtype)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 1125, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 1457, in _mul_dispatch\n    return multiply(x, y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 509, in multiply\n    return gen_math_ops.mul(x, y, name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 6176, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rNiwlHvVgq",
        "outputId": "92c89a39-b7f1-4f33-ebd7-fff8691327e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy.special import softmax\n",
        "m = softmax([[230   , 1000]])\n",
        "print(m)"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L25DzbJjHKl2"
      },
      "source": [
        "kaggle datasets download -d thanhlong1997/word2vec-vn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAxiLT0UMSy5",
        "outputId": "544a096f-b1e3-4ced-ea2b-7736565a8b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgNhMVfKutUy",
        "outputId": "f78b52d9-7b21-4f91-a76c-9441f27042e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(data[1000])"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': '* Hàng cực hot hoàn thiện đẹp trước tết về ở luôn chỉ 1 căn duy nhất . LH xem nhà : A Thủy 0939965555/0379500000 ... (Tặng 2 phiếu bốc thăm trúng xe Vision trị giá 40tr khi mua nhà của cty chúng tôi) ... * Nhà Phú Lãm xây 3 tầng 35m2 ngõ thông ô tô đỗ 10m đã hoàn thiện giá chỉ 1,63 tỷ (ảnh thật 100%) ... Thiết kế gồm : . Tầng 1 : Phòng khách , bếp , 1 nhà vệ sinh ... Tầng 2 : 2 phòng ngủ , 1 vệ sinh ... Tầng 3 : 1 phòng thờ (phòng ngủ), 1 sân phơi rộng thoáng ... Thiết kế và xây dựng do kiến trúc sư tính toán tối đa công năng sử dụng và rất tiện ích ... Nhà được xây có móng riêng , cột riêng , tường riêng . Đảm bảo an toàn và sửa chữa . Có thể xây thêm tầng 4,5 thoải mái ... Sổ đỏ và giấy phép xây dựng đầy đủ ... * Nội thất cao cấp đầy đủ nội thất cơ bản về chỉ việc ở như hệ thống điện nước , tủ bếp , vệ sinh , trần thạch cao .. ... * Vị trí và tiện ích là 2 yếu tố chính mà mỗi người mua nhà đều quan tâm nhất thì ở đây đáp ứng được đầy đủ các yêu cầu đó ... Nhà gần Quốc lộ 21B , gần chợ , trường học , UBND phường , nhà văn hóa , khu dân cư văn minh , an toàn ... Đường vào rộng 3m , chỗ để ô tô cách nhà 30m ... Kích thước khá đẹp : 3,75mx9,08m ... Giá : 1,63 tỷ (bao toàn bộ phí sang tên cho người mua) ... Liên hệ ngay : 0939965555/0379500000 a Thủy xem nhà ... Hỗ trợ làm KT3 và thủ tục nhập học cho các cháu .', 'labels': [[84, 90, 'contact_name'], [91, 112, 'contact_mobile'], [173, 176, 'type'], [210, 217, 'location'], [222, 228, 'floor'], [229, 233, 'size'], [278, 285, 'price'], [323, 329, 'number_floor'], [332, 343, 'number_livingroom'], [346, 349, 'number_kitchen'], [352, 365, 'number_dressroom'], [370, 376, 'number_floor'], [379, 390, 'number_bedroom'], [393, 402, 'number_dressroom'], [407, 413, 'number_floor'], [416, 427, 'san_phoi_thuong'], [441, 451, 'san_phoi_thuong'], [661, 669, 'number_floor'], [684, 689, 'legal'], [897, 900, 'type'], [980, 991, 'near_places'], [1094, 1096, 'size_mat_ngo'], [1149, 1160, 'size_mat_ngo'], [1171, 1204, 'price'], [1215, 1218, 'type'], [1239, 1260, 'contact_mobile'], [1261, 1267, 'contact_name']]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJsj6EgjCWh"
      },
      "source": [
        "\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    tf.reset_default_graph()\n",
        "    self.n_hidden_1 = 256\n",
        "    self.n_hidden_2 = 64\n",
        "    self.dimention_1 = 26 # dimention of vocabulary\n",
        "    self.dimention_2 = 7 # dimention of entities\n",
        "    self.connect_dimention = 16 # dimention connect\n",
        "    self.num_class = 2\n",
        "    self.keep_prob = 1\n",
        "    \n",
        "\n",
        "      # tf Graph input\n",
        "    self.X_11 = tf.placeholder('float',[None,self.dimention_1],name='X_11')\n",
        "    self.X_21 = tf.placeholder('float',[None,self.dimention_2],name='X_21')\n",
        "    self.Y1   = tf.placeholder('float',[None,self.num_class],name='Y1')\n",
        "\n",
        "    self.weights = {\n",
        "        'concat_1': tf.Variable(tf.random_normal([self.dimention_1,self.connect_dimention]),name='concat_1'),\n",
        "        'concat_2': tf.Variable(tf.random_normal([self.dimention_2,self.connect_dimention]),name='concat_2'),\n",
        "        'h_1'     : tf.Variable(tf.random_normal([self.connect_dimention,self.n_hidden_1]),name='h_1'),\n",
        "        'h_2'     : tf.Variable(tf.random_normal([self.n_hidden_1,self.n_hidden_2]),name='h_2'),\n",
        "        'out'     : tf.Variable(tf.random_normal([self.n_hidden_2,self.num_class]),name='out')\n",
        "    }\n",
        "\n",
        "    self.biases = {\n",
        "        'b_1' : tf.Variable(tf.random_normal([self.n_hidden_1]),name='b_1'),\n",
        "        'b_2' : tf.Variable(tf.random_normal([self.n_hidden_2]),name='b_2'),\n",
        "        'out' : tf.Variable(tf.random_normal([self.num_class]),name='out')\n",
        "    }\n",
        "    self.predict, self.prob = self.neural_net(self.X_11,self.X_21)\n",
        "    self.initialize_and_restore_session()\n",
        "\n",
        "  def neural_net(self,x1,x2):\n",
        "    # Concat Feature\n",
        "    concat  = tf.add(tf.matmul(x1,self.weights['concat_1']),tf.matmul(x2,self.weights['concat_2']))\n",
        "    # hidden layer 1\n",
        "    layer_1 = tf.add(tf.matmul(concat,self.weights['h_1']),self.biases['b_1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    # hidden layer 2\n",
        "    layer_2 = tf.add(tf.matmul(layer_1,self.weights['h_2']),self.biases['b_2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    # drop out\n",
        "    drop_out = tf.nn.dropout(layer_2,self.keep_prob)\n",
        "    # out layer\n",
        "    out_layer = tf.add(tf.matmul(drop_out,self.weights['out']),self.biases['out'])\n",
        "    probabilities = tf.nn.softmax(out_layer, axis=-1)\n",
        "    return out_layer , probabilities\n",
        "\n",
        "  def initialize_and_restore_session(self):\n",
        "        \"\"\"Defines self.sess and initialize the variables\"\"\"\n",
        "        print(\"Initializing tf session\")\n",
        "        # config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, device_count={'GPU': 0})\n",
        "        # config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        self.saver = tf.train.Saver()\n",
        "        self.saver.restore(self.sess, '/content/model/model195.ckpt')\n",
        "        print(\"Complete restore model from \")\n",
        "\n",
        "  def predict_raw_text(self,input):\n",
        "    # print(input['text'])\n",
        "    # text = input['text']\n",
        "    # graph_meta = tf.train.import_meta_graph('/content/model/model95.ckpt.meta')\n",
        "    predict = tf.argmax(self.predict, 1)\n",
        "    vector1 = transform_document_to_vec(input)\n",
        "    vector2,slot = transform_entity_to_vec(input)\n",
        "    vector2 = vector2.reshape([1,7])\n",
        "    pred , prop = self.sess.run([predict,self.prob],feed_dict={self.X_11: vector1,\n",
        "                                        self.X_21: vector2})\n",
        "    print(pred , prob)\n",
        "    return pred\n",
        "\n",
        "\n",
        "# print(predict_raw_text('Bán gấp nhà Văn Điển 5 tầng ô tô đỗ gần chỉ 2,7 tỷ ... + Nhà mới đẹp Văn Điển ở ngay , ô tô đỗ gần , công năng đầy đủ cho 1 hộ gia đình ở : 1 khách , bếp , 2 ngủ , 3wc , phòng thờ , sân phơi . Có thể lên thêm 2 tầng thoải mái ... + Nhà Văn Điển gần rất nhiều tiện ích : chợ , trung tâm thương mại , bệnh viện , trung tâm thể dục thể thao , huyện ủy thanh trì ... + Khu vực Thanh Trì sắp lên Quận giá trị bất động sản ngày một tang , khách mua năm sbawts tình hình mua đợt này dịch giá có bớt cho ai thiện chí ... + Khu vực Thanh trì lên trung tâm thành phố rất gần chỉ 15 phút , đi các quận rất thuận tiện , về quê qua bến xe nước ngầm chỉ 2 phút ... + Nhà đẹp sổ vuông nở hậu ... + Liên hệ Mrs Thúy : 0965 - 2535 - 83'))\n",
        "# 1/0\n",
        "\n"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl2xfdBVmYyA",
        "outputId": "f5c39ab7-80dd-42c5-e895-9621425665a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = Model()\n",
        "print(model.predict_raw_text(data[1000]))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing tf session\n",
            "INFO:tensorflow:Restoring parameters from /content/model/model195.ckpt\n",
            "Complete restore model from \n",
            "[array([1])]\n",
            "[array([1])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNJFyE70Q0_k"
      },
      "source": [
        "import json\n",
        "with open('/content/result4700.json','r',encoding='utf-8') as file:\n",
        "  data_test = json.load(file)\n",
        "result = []\n",
        "for index in range(1000,1100):\n",
        "  result.append(predict_raw_text(data[index]))\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYodTGT5VbkZ",
        "outputId": "879a6b9b-7334-41d3-9b04-382865ea08f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(result[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcbp_Rl-aly",
        "outputId": "16bc5485-fc0a-4628-da26-f9816508c343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for index in range(len(result)):\n",
        "  if result[index] == 1:\n",
        "    print(index+1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1018\n",
            "1049\n",
            "1061\n",
            "1067\n",
            "1069\n",
            "1073\n",
            "1085\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}